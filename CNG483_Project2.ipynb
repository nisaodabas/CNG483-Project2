{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNG483-Project2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrvsheU7eaKf7ju7hbKnWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisaodabas/CNG483-Project2/blob/master/CNG483_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzPhI0ARvc2S",
        "colab_type": "code",
        "outputId": "90a38387-d88d-4fb3-9661-d892579807a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import cross_val_score, KFold, train_test_split, GridSearchCV\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model  \n",
        "from keras.utils import np_utils\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAKG704tnQTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seed value\n",
        "# Apparently you may use different seed values at each stage\n",
        "seed_value= 1\n",
        "\n",
        "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed_value)\n",
        "# for later versions: \n",
        "# tf.compat.v1.set_random_seed(seed_value)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuVsk-f_o2fU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createDataSet(path):\n",
        "    df = pd.read_csv(path, sep='\\n')\n",
        "    data = np.array(df)\n",
        "\n",
        "    #print(data)\n",
        "    numAttr = 0\n",
        "    rows = []\n",
        "    for row in data:        \n",
        "        found = row[0].find(\"@ATTRIBUTE\")\n",
        "        if(found != -1):\n",
        "            numAttr += 1\n",
        "        else:\n",
        "            # ignore @ATTRIBUTE rows\n",
        "            rows.append(row[0].split(\",\"))\n",
        "\n",
        "    # delete @DATA row\n",
        "    rows = np.array(rows[1:])\n",
        "\n",
        "    labels = rows[:, -1].astype('int')\n",
        "    \n",
        "    labels = np.array([x - 1 for x in labels])\n",
        "\n",
        "    if(numAttr == 6):\n",
        "        features = rows[:, :numAttr-1].astype('float')\n",
        "    else:\n",
        "        features = rows[:, :numAttr-1].astype('int')\n",
        "        # define feature selection\n",
        "        #fs = SelectKBest(score_func=f_classif, k=4000)\n",
        "        # apply feature selection\n",
        "        #features = fs.fit_transform(features, labels)\n",
        "        \n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvKkK7eufEZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X, y, dim):\n",
        "    \n",
        "    # define model\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=1)\n",
        "    \n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', kernel_initializer='he_normal', input_dim=dim))\n",
        "\n",
        "    model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
        "    \n",
        "    #model.add(Dropout(0.1))\n",
        "    \n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
        "    #model.add(Dropout(0.1))\n",
        "    \n",
        "    model.add(Dense(64, activation='relu', kernel_initializer='he_normal'))\n",
        "    #model.add(Dropout(0.1))\n",
        "    \n",
        "    model.add(Dense(32, activation='relu', kernel_initializer='he_normal'))\n",
        "    #model.add(Dropout(0.1))\n",
        "    \n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    # compile the model\n",
        "    opt = RMSprop(learning_rate=0.0001, rho=0.9, momentum=0.0)\n",
        "    #model.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "    \n",
        "    # simple early stopping\n",
        "    #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "    #mc = ModelCheckpoint('/content/drive/My Drive/CNG483-Project 2/best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "    \n",
        "    numEpochs = 1000\n",
        "    batches = 128\n",
        "\n",
        "\n",
        "    \n",
        "    # fit model , callbacks=[es]\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=numEpochs, batch_size=batches, verbose=1)\n",
        "\n",
        "    # evaluate the model\n",
        "    _, train_acc = model.evaluate(X_train, y_train, batch_size=batches, verbose=0)\n",
        "    _, test_acc = model.evaluate(X_val, y_val, batch_size=batches, verbose=0)\n",
        "    print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "    \n",
        "    \n",
        "    \n",
        "    '''\n",
        "    history = model.fit(X_train, y_train, epochs=numEpochs, batch_size=batches, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    #print(history.history.keys())\n",
        "    '''\n",
        "    loss_train = history.history['loss']\n",
        "    loss_val = history.history['val_loss']\n",
        "    epochs = range(1,numEpochs+1)\n",
        "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "    plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    acc_train = history.history['acc']\n",
        "    acc_val = history.history['val_acc']\n",
        "    epochs = range(1,numEpochs+1)\n",
        "    plt.plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "    plt.plot(epochs, acc_val, 'b', label='validation accuracy')\n",
        "    plt.title('Training and Validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    #return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "604NK7OdyJcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gridSearch(X, y):\n",
        "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "    # define the grid search parameters\n",
        "    batch_size = [10, 20, 40, 60, 80, 100]\n",
        "    epochs = [10, 50, 100]\n",
        "    param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "    grid_result = grid.fit(X, Y)\n",
        "    # summarize results\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    stds = grid_result.cv_results_['std_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "        print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYvDVzZ85X9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    geometic_test_path = \"/content/drive/My Drive/CNG483-Project 2/IrisGeometicFeatures_TestingSet.txt\"\n",
        "    geometic_train_path = \"/content/drive/My Drive/CNG483-Project 2/IrisGeometicFeatures_TrainingSet.txt\"\n",
        "\n",
        "    texture_test_path = \"/content/drive/My Drive/CNG483-Project 2/IrisTextureFeatures_TestingSet.txt\"\n",
        "    texture_train_path = \"/content/drive/My Drive/CNG483-Project 2/IrisTextureFeatures_TrainingSet.txt\"\n",
        "\n",
        "\n",
        "    geo_x_train, geo_y_train = createDataSet(geometic_train_path)\n",
        "    geo_x_test, geo_y_test = createDataSet(geometic_test_path)\n",
        "\n",
        "    txtr_x_train, txtr_y_train = createDataSet(texture_train_path)\n",
        "    txtr_x_test, txtr_y_test = createDataSet(texture_test_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRiVV5quCLjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    all_x_train = np.concatenate((txtr_x_train, geo_x_train), axis=1)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbd6UrHdHPa8",
        "colab_type": "code",
        "outputId": "e1d1c30b-820b-4709-bdb9-fe2c65703965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    #model(txtr_x_train, txtr_y_train, 9600)\n",
        "    #model(geo_x_train, geo_y_train, 5)\n",
        "    model(all_x_train, txtr_y_train, 9605)\n",
        "\n",
        "    #conv1d(txtr_x_train, txtr_y_train, 9600)\n",
        "\n",
        "\n",
        "    '''\n",
        "    estimator = KerasClassifier(build_fn=model, epochs=975, batch_size=128, verbose=0)\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "    results = cross_val_score(estimator, all_x_train, txtr_y_train, cv=kfold, scoring='accuracy')\n",
        "\n",
        "    print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "    '''\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 119.9885 - acc: 0.4448 - val_loss: 62.5073 - val_acc: 0.5721\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 55.8907 - acc: 0.4678 - val_loss: 145.7918 - val_acc: 0.5721\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 80.5538 - acc: 0.4940 - val_loss: 82.0044 - val_acc: 0.5721\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 60.7565 - acc: 0.4568 - val_loss: 23.7442 - val_acc: 0.3493\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 54.8523 - acc: 0.4328 - val_loss: 62.0778 - val_acc: 0.5721\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 59.3122 - acc: 0.4798 - val_loss: 54.7954 - val_acc: 0.5721\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 61.8080 - acc: 0.4361 - val_loss: 82.2869 - val_acc: 0.3493\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 58.9302 - acc: 0.4055 - val_loss: 6.5283 - val_acc: 0.5721\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 57.7252 - acc: 0.4710 - val_loss: 65.5091 - val_acc: 0.0786\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 53.8478 - acc: 0.4175 - val_loss: 35.0317 - val_acc: 0.5721\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 56.9683 - acc: 0.4240 - val_loss: 87.7280 - val_acc: 0.5721\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 53.8970 - acc: 0.4459 - val_loss: 56.9177 - val_acc: 0.3493\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 59.3872 - acc: 0.4918 - val_loss: 40.5705 - val_acc: 0.3493\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 52.0815 - acc: 0.4011 - val_loss: 35.9436 - val_acc: 0.5721\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 51.3107 - acc: 0.4776 - val_loss: 57.3831 - val_acc: 0.0786\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 48.3193 - acc: 0.4240 - val_loss: 49.2743 - val_acc: 0.5721\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 51.5609 - acc: 0.4372 - val_loss: 107.3188 - val_acc: 0.3493\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 55.8024 - acc: 0.4787 - val_loss: 28.6019 - val_acc: 0.3493\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 48.1603 - acc: 0.4995 - val_loss: 10.2874 - val_acc: 0.5721\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 48.3672 - acc: 0.4372 - val_loss: 67.4369 - val_acc: 0.5721\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 47.2583 - acc: 0.5126 - val_loss: 32.9778 - val_acc: 0.0786\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 49.6640 - acc: 0.4415 - val_loss: 93.6111 - val_acc: 0.5721\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 56.2863 - acc: 0.4273 - val_loss: 11.4426 - val_acc: 0.5721\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 44.9037 - acc: 0.4186 - val_loss: 59.3476 - val_acc: 0.5721\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 41.4269 - acc: 0.5552 - val_loss: 35.8446 - val_acc: 0.3493\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 47.0896 - acc: 0.4306 - val_loss: 49.5115 - val_acc: 0.5721\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 47.0109 - acc: 0.4186 - val_loss: 98.5252 - val_acc: 0.3493\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 44.5582 - acc: 0.4962 - val_loss: 36.4580 - val_acc: 0.5721\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 45.2211 - acc: 0.4404 - val_loss: 101.1436 - val_acc: 0.5721\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 51.8538 - acc: 0.5071 - val_loss: 18.7129 - val_acc: 0.5721\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 48.5915 - acc: 0.4798 - val_loss: 14.4578 - val_acc: 0.0786\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 44.8406 - acc: 0.4372 - val_loss: 47.4622 - val_acc: 0.5721\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 44.6915 - acc: 0.4295 - val_loss: 115.1581 - val_acc: 0.3493\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 59.9177 - acc: 0.4448 - val_loss: 63.5379 - val_acc: 0.5721\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 44.0751 - acc: 0.4426 - val_loss: 71.5624 - val_acc: 0.3493\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 51.1739 - acc: 0.4448 - val_loss: 28.2003 - val_acc: 0.5721\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 48.0011 - acc: 0.4645 - val_loss: 18.0737 - val_acc: 0.3493\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 38.9146 - acc: 0.4251 - val_loss: 46.2804 - val_acc: 0.5721\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 40.9402 - acc: 0.4350 - val_loss: 57.8720 - val_acc: 0.3493\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 49.0119 - acc: 0.4732 - val_loss: 31.9310 - val_acc: 0.3493\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 38.9754 - acc: 0.4699 - val_loss: 87.4568 - val_acc: 0.3493\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 43.8236 - acc: 0.4339 - val_loss: 21.1576 - val_acc: 0.3493\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 45.2510 - acc: 0.4787 - val_loss: 30.1616 - val_acc: 0.3493\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 41.9705 - acc: 0.3967 - val_loss: 5.6383 - val_acc: 0.5721\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 35.6500 - acc: 0.4393 - val_loss: 54.3949 - val_acc: 0.5721\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 38.8157 - acc: 0.5279 - val_loss: 48.5062 - val_acc: 0.5721\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 46.3899 - acc: 0.4230 - val_loss: 57.5497 - val_acc: 0.3493\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 41.7392 - acc: 0.4011 - val_loss: 23.9426 - val_acc: 0.5721\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 34.2406 - acc: 0.5213 - val_loss: 80.2412 - val_acc: 0.5721\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 41.7174 - acc: 0.4612 - val_loss: 33.1950 - val_acc: 0.3493\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 51.5869 - acc: 0.4525 - val_loss: 24.7908 - val_acc: 0.3493\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 38.9643 - acc: 0.3956 - val_loss: 22.4114 - val_acc: 0.5721\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 34.4868 - acc: 0.4962 - val_loss: 48.3371 - val_acc: 0.0786\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 36.6749 - acc: 0.4568 - val_loss: 54.4117 - val_acc: 0.5721\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 40.8176 - acc: 0.4383 - val_loss: 75.9303 - val_acc: 0.3493\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 43.0373 - acc: 0.4678 - val_loss: 14.3674 - val_acc: 0.5721\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 41.2321 - acc: 0.4918 - val_loss: 7.0357 - val_acc: 0.5721\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 33.8812 - acc: 0.4536 - val_loss: 62.2047 - val_acc: 0.5721\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 39.6205 - acc: 0.5191 - val_loss: 68.5865 - val_acc: 0.5721\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 38.8990 - acc: 0.4590 - val_loss: 46.0244 - val_acc: 0.3493\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 31.9850 - acc: 0.4721 - val_loss: 99.1210 - val_acc: 0.3493\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 47.1702 - acc: 0.4699 - val_loss: 56.4902 - val_acc: 0.5721\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 37.4351 - acc: 0.4885 - val_loss: 6.9908 - val_acc: 0.6594\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 34.8739 - acc: 0.4776 - val_loss: 12.2667 - val_acc: 0.5721\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 32.5690 - acc: 0.4459 - val_loss: 49.1418 - val_acc: 0.5721\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 35.2157 - acc: 0.4940 - val_loss: 62.0300 - val_acc: 0.5721\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 37.0048 - acc: 0.4426 - val_loss: 27.4057 - val_acc: 0.3493\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 32.1474 - acc: 0.5027 - val_loss: 7.8894 - val_acc: 0.6201\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 34.5395 - acc: 0.4973 - val_loss: 11.1219 - val_acc: 0.5721\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 36.4958 - acc: 0.4437 - val_loss: 41.1704 - val_acc: 0.5721\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 33.4302 - acc: 0.4481 - val_loss: 45.0261 - val_acc: 0.3493\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 37.0466 - acc: 0.4885 - val_loss: 63.4610 - val_acc: 0.3493\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 30.1246 - acc: 0.4721 - val_loss: 24.3273 - val_acc: 0.5721\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 32.4297 - acc: 0.4601 - val_loss: 74.1090 - val_acc: 0.3493\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 32.3481 - acc: 0.4459 - val_loss: 12.8533 - val_acc: 0.5721\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 29.8159 - acc: 0.5049 - val_loss: 16.1787 - val_acc: 0.2838\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 30.4189 - acc: 0.4852 - val_loss: 28.9236 - val_acc: 0.5721\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 36.6114 - acc: 0.4295 - val_loss: 33.3710 - val_acc: 0.3493\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 29.8345 - acc: 0.4262 - val_loss: 4.5121 - val_acc: 0.6332\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 24.1774 - acc: 0.4678 - val_loss: 53.1806 - val_acc: 0.5721\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 30.1511 - acc: 0.5257 - val_loss: 40.9500 - val_acc: 0.5721\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 38.8033 - acc: 0.4372 - val_loss: 27.5932 - val_acc: 0.3493\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 27.4519 - acc: 0.4262 - val_loss: 14.1082 - val_acc: 0.3493\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 31.2487 - acc: 0.4863 - val_loss: 25.3752 - val_acc: 0.3493\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 27.2195 - acc: 0.4874 - val_loss: 44.4636 - val_acc: 0.3493\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 34.2573 - acc: 0.3989 - val_loss: 20.7739 - val_acc: 0.5721\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 26.9311 - acc: 0.5333 - val_loss: 27.9382 - val_acc: 0.5721\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 30.2794 - acc: 0.4721 - val_loss: 40.5288 - val_acc: 0.3493\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 28.4683 - acc: 0.4361 - val_loss: 6.9483 - val_acc: 0.5895\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 31.9926 - acc: 0.4743 - val_loss: 25.5090 - val_acc: 0.0786\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 26.6478 - acc: 0.4645 - val_loss: 29.4279 - val_acc: 0.5721\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 27.0414 - acc: 0.4514 - val_loss: 40.2275 - val_acc: 0.5721\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 24.3459 - acc: 0.4995 - val_loss: 3.1015 - val_acc: 0.4760\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 23.3109 - acc: 0.4798 - val_loss: 21.6691 - val_acc: 0.0873\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 28.9741 - acc: 0.4350 - val_loss: 51.0869 - val_acc: 0.5721\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 23.1742 - acc: 0.4787 - val_loss: 28.8525 - val_acc: 0.5721\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 27.2289 - acc: 0.4863 - val_loss: 9.7577 - val_acc: 0.5066\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 25.6133 - acc: 0.4131 - val_loss: 58.2975 - val_acc: 0.3493\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 29.1421 - acc: 0.5104 - val_loss: 23.2889 - val_acc: 0.3493\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 26.2105 - acc: 0.4262 - val_loss: 4.0672 - val_acc: 0.6070\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 22.8390 - acc: 0.5038 - val_loss: 63.3185 - val_acc: 0.3493\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 28.2004 - acc: 0.4874 - val_loss: 9.7492 - val_acc: 0.5808\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 32.2768 - acc: 0.4874 - val_loss: 14.6988 - val_acc: 0.5721\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 31.9280 - acc: 0.4328 - val_loss: 45.5808 - val_acc: 0.5721\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 24.2753 - acc: 0.4678 - val_loss: 36.9973 - val_acc: 0.3493\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 28.9588 - acc: 0.4393 - val_loss: 11.1112 - val_acc: 0.5721\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 24.6904 - acc: 0.5246 - val_loss: 30.3469 - val_acc: 0.3493\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 23.2843 - acc: 0.4831 - val_loss: 11.3050 - val_acc: 0.5721\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 22.5409 - acc: 0.5202 - val_loss: 29.3786 - val_acc: 0.5721\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 22.2928 - acc: 0.4710 - val_loss: 14.7782 - val_acc: 0.3493\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 22.0082 - acc: 0.4339 - val_loss: 30.4815 - val_acc: 0.5721\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 23.4196 - acc: 0.4295 - val_loss: 32.9167 - val_acc: 0.3493\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 25.1047 - acc: 0.4710 - val_loss: 39.3541 - val_acc: 0.3493\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 23.0134 - acc: 0.4328 - val_loss: 9.0528 - val_acc: 0.3493\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 19.1579 - acc: 0.4481 - val_loss: 26.5839 - val_acc: 0.5721\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 22.6745 - acc: 0.4984 - val_loss: 13.7554 - val_acc: 0.5066\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 20.2298 - acc: 0.4623 - val_loss: 7.2075 - val_acc: 0.5764\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 24.6561 - acc: 0.4721 - val_loss: 8.3931 - val_acc: 0.3493\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 19.0988 - acc: 0.4678 - val_loss: 33.2120 - val_acc: 0.3493\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 23.6244 - acc: 0.4612 - val_loss: 14.1967 - val_acc: 0.5721\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 27.1023 - acc: 0.4689 - val_loss: 46.2827 - val_acc: 0.3493\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 27.5064 - acc: 0.4186 - val_loss: 14.2130 - val_acc: 0.2445\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 19.4525 - acc: 0.4481 - val_loss: 25.8605 - val_acc: 0.5721\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 19.8230 - acc: 0.4623 - val_loss: 5.9207 - val_acc: 0.3493\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 16.1469 - acc: 0.4656 - val_loss: 22.4433 - val_acc: 0.5721\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 19.2302 - acc: 0.4831 - val_loss: 18.7894 - val_acc: 0.0786\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 21.3996 - acc: 0.4393 - val_loss: 32.4597 - val_acc: 0.5721\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 23.4432 - acc: 0.4197 - val_loss: 24.3193 - val_acc: 0.3493\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 21.2399 - acc: 0.4689 - val_loss: 32.4697 - val_acc: 0.5721\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 18.9770 - acc: 0.5792 - val_loss: 1.6988 - val_acc: 0.6376\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 17.9910 - acc: 0.4787 - val_loss: 29.5289 - val_acc: 0.5721\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 18.7710 - acc: 0.4601 - val_loss: 38.2989 - val_acc: 0.3493\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 23.2853 - acc: 0.4852 - val_loss: 33.7329 - val_acc: 0.5721\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 17.5309 - acc: 0.4699 - val_loss: 15.0656 - val_acc: 0.5721\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 17.2488 - acc: 0.5344 - val_loss: 13.7525 - val_acc: 0.0786\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 20.2899 - acc: 0.4546 - val_loss: 25.7134 - val_acc: 0.3493\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 21.9435 - acc: 0.4230 - val_loss: 8.8688 - val_acc: 0.3493\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 16.5568 - acc: 0.4361 - val_loss: 26.1120 - val_acc: 0.5721\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 15.4480 - acc: 0.5454 - val_loss: 28.2151 - val_acc: 0.5721\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 19.5648 - acc: 0.5148 - val_loss: 5.8228 - val_acc: 0.5721\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 21.1373 - acc: 0.4142 - val_loss: 26.0229 - val_acc: 0.5721\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 18.8468 - acc: 0.4317 - val_loss: 32.2326 - val_acc: 0.3493\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 21.8010 - acc: 0.4601 - val_loss: 21.7207 - val_acc: 0.5721\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 19.0277 - acc: 0.4317 - val_loss: 17.4223 - val_acc: 0.3493\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 17.4281 - acc: 0.4087 - val_loss: 6.4030 - val_acc: 0.5721\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 16.7674 - acc: 0.4874 - val_loss: 15.4449 - val_acc: 0.0786\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 16.6676 - acc: 0.4732 - val_loss: 32.3646 - val_acc: 0.5721\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 17.0827 - acc: 0.4557 - val_loss: 4.9807 - val_acc: 0.5721\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 17.8158 - acc: 0.4634 - val_loss: 34.3303 - val_acc: 0.0786\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 16.7024 - acc: 0.4579 - val_loss: 14.0975 - val_acc: 0.4061\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 12.9845 - acc: 0.4612 - val_loss: 17.2956 - val_acc: 0.3493\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 16.5368 - acc: 0.4732 - val_loss: 13.9930 - val_acc: 0.5721\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 14.9943 - acc: 0.5027 - val_loss: 11.1924 - val_acc: 0.5721\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 15.0176 - acc: 0.4426 - val_loss: 34.6619 - val_acc: 0.5721\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 17.5370 - acc: 0.5049 - val_loss: 6.4108 - val_acc: 0.4978\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 15.0390 - acc: 0.5279 - val_loss: 13.2192 - val_acc: 0.5721\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 15.4069 - acc: 0.4546 - val_loss: 25.1004 - val_acc: 0.5721\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 14.4030 - acc: 0.4623 - val_loss: 24.7667 - val_acc: 0.3493\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 16.6660 - acc: 0.4765 - val_loss: 7.7343 - val_acc: 0.5808\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 15.5802 - acc: 0.4973 - val_loss: 2.2107 - val_acc: 0.6376\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 14.4057 - acc: 0.4459 - val_loss: 25.4459 - val_acc: 0.5721\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 14.7959 - acc: 0.4918 - val_loss: 27.5552 - val_acc: 0.3493\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 17.5552 - acc: 0.3825 - val_loss: 11.4062 - val_acc: 0.3493\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 14.3357 - acc: 0.4765 - val_loss: 11.4882 - val_acc: 0.3493\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 14.6366 - acc: 0.5126 - val_loss: 21.8125 - val_acc: 0.3493\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 12.0579 - acc: 0.5115 - val_loss: 22.3607 - val_acc: 0.5721\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 14.6506 - acc: 0.4459 - val_loss: 17.1867 - val_acc: 0.3493\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 10.6069 - acc: 0.5803 - val_loss: 7.7470 - val_acc: 0.5240\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 13.4687 - acc: 0.4415 - val_loss: 8.9610 - val_acc: 0.3493\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 15.2306 - acc: 0.4820 - val_loss: 21.9426 - val_acc: 0.3493\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 12.8723 - acc: 0.4809 - val_loss: 21.2743 - val_acc: 0.3406\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 13.6871 - acc: 0.4361 - val_loss: 30.3291 - val_acc: 0.5721\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 18.2637 - acc: 0.4863 - val_loss: 29.6942 - val_acc: 0.5721\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 14.6821 - acc: 0.4896 - val_loss: 18.1233 - val_acc: 0.3493\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 10.9655 - acc: 0.4656 - val_loss: 12.6040 - val_acc: 0.5721\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 11.6846 - acc: 0.4164 - val_loss: 28.0080 - val_acc: 0.5721\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 15.9173 - acc: 0.5115 - val_loss: 7.0253 - val_acc: 0.1616\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 13.3277 - acc: 0.4590 - val_loss: 8.8470 - val_acc: 0.5721\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 11.2828 - acc: 0.4852 - val_loss: 29.0168 - val_acc: 0.3493\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 14.5314 - acc: 0.4623 - val_loss: 6.2649 - val_acc: 0.4017\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 10.7702 - acc: 0.5355 - val_loss: 13.2664 - val_acc: 0.5721\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 12.7694 - acc: 0.4459 - val_loss: 22.7717 - val_acc: 0.5721\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 11.8626 - acc: 0.5180 - val_loss: 2.2089 - val_acc: 0.6026\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 12.3291 - acc: 0.4251 - val_loss: 21.1891 - val_acc: 0.5721\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 12.3806 - acc: 0.5268 - val_loss: 8.0724 - val_acc: 0.3493\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 12.6239 - acc: 0.4842 - val_loss: 19.9110 - val_acc: 0.3493\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 11.1398 - acc: 0.4667 - val_loss: 10.6377 - val_acc: 0.5721\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 9.8917 - acc: 0.4678 - val_loss: 11.5664 - val_acc: 0.5721\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 13.7133 - acc: 0.4426 - val_loss: 8.2962 - val_acc: 0.5721\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 9.5062 - acc: 0.5541 - val_loss: 17.6763 - val_acc: 0.0786\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 18.7801 - acc: 0.4525 - val_loss: 13.1824 - val_acc: 0.3493\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 11.1689 - acc: 0.4437 - val_loss: 1.0734 - val_acc: 0.5633\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 8.0216 - acc: 0.5180 - val_loss: 16.6110 - val_acc: 0.5721\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 10.4564 - acc: 0.5158 - val_loss: 12.0582 - val_acc: 0.5721\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 11.2609 - acc: 0.4929 - val_loss: 2.0307 - val_acc: 0.5939\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 11.2494 - acc: 0.4372 - val_loss: 17.6804 - val_acc: 0.5721\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.3485 - acc: 0.6044 - val_loss: 4.2805 - val_acc: 0.5721\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 10.5279 - acc: 0.4525 - val_loss: 1.8676 - val_acc: 0.5808\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 11.1586 - acc: 0.4656 - val_loss: 20.3638 - val_acc: 0.5721\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 10.8699 - acc: 0.5279 - val_loss: 11.2561 - val_acc: 0.5721\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 10.2229 - acc: 0.5301 - val_loss: 12.5008 - val_acc: 0.3493\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 11.6340 - acc: 0.4044 - val_loss: 10.5970 - val_acc: 0.5721\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 10.2259 - acc: 0.4896 - val_loss: 14.4058 - val_acc: 0.0786\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 12.5594 - acc: 0.4361 - val_loss: 13.8429 - val_acc: 0.5721\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 10.6981 - acc: 0.4536 - val_loss: 13.5724 - val_acc: 0.3493\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 9.0241 - acc: 0.4481 - val_loss: 10.6978 - val_acc: 0.5721\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 8.8914 - acc: 0.4437 - val_loss: 16.4227 - val_acc: 0.3493\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 10.0237 - acc: 0.5290 - val_loss: 7.6183 - val_acc: 0.5721\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 9.5257 - acc: 0.4557 - val_loss: 13.9271 - val_acc: 0.5721\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 14.6620 - acc: 0.5071 - val_loss: 16.2272 - val_acc: 0.5328\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 9.8303 - acc: 0.5126 - val_loss: 5.8221 - val_acc: 0.5808\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 16.3545 - acc: 0.4601 - val_loss: 35.1177 - val_acc: 0.3493\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 12.5022 - acc: 0.4896 - val_loss: 6.7659 - val_acc: 0.5721\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 8.8890 - acc: 0.4601 - val_loss: 17.8497 - val_acc: 0.3493\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 11.0412 - acc: 0.4579 - val_loss: 12.8614 - val_acc: 0.5721\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 8.3068 - acc: 0.5027 - val_loss: 13.0358 - val_acc: 0.5721\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.8657 - acc: 0.5847 - val_loss: 2.2507 - val_acc: 0.4760\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.8477 - acc: 0.4645 - val_loss: 15.0082 - val_acc: 0.3493\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 9.6355 - acc: 0.5126 - val_loss: 6.3064 - val_acc: 0.5721\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 11.0951 - acc: 0.4536 - val_loss: 11.7399 - val_acc: 0.5721\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 8.2445 - acc: 0.5093 - val_loss: 3.7968 - val_acc: 0.5721\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.9318 - acc: 0.4623 - val_loss: 2.7695 - val_acc: 0.6201\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 6.8929 - acc: 0.5016 - val_loss: 6.0129 - val_acc: 0.5852\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 9.5367 - acc: 0.4863 - val_loss: 1.8311 - val_acc: 0.6201\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 7.5156 - acc: 0.4503 - val_loss: 10.4704 - val_acc: 0.5721\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 5.7346 - acc: 0.5148 - val_loss: 12.9817 - val_acc: 0.5721\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.2332 - acc: 0.5257 - val_loss: 15.6009 - val_acc: 0.3493\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.6062 - acc: 0.5093 - val_loss: 8.0682 - val_acc: 0.3493\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 10.0486 - acc: 0.4820 - val_loss: 47.0453 - val_acc: 0.3493\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 16.6998 - acc: 0.4962 - val_loss: 13.5049 - val_acc: 0.5721\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 5.6576 - acc: 0.5934 - val_loss: 5.1664 - val_acc: 0.6376\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 8.7788 - acc: 0.5836 - val_loss: 8.1659 - val_acc: 0.5721\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 9.1621 - acc: 0.4284 - val_loss: 18.5009 - val_acc: 0.5721\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 8.6452 - acc: 0.5246 - val_loss: 5.4020 - val_acc: 0.4367\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 9.6017 - acc: 0.5322 - val_loss: 9.7326 - val_acc: 0.3493\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 10.4053 - acc: 0.4240 - val_loss: 7.7017 - val_acc: 0.5721\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.7467 - acc: 0.5224 - val_loss: 3.7742 - val_acc: 0.6114\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 7.6300 - acc: 0.5727 - val_loss: 10.9569 - val_acc: 0.5721\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 9.5593 - acc: 0.4459 - val_loss: 11.0711 - val_acc: 0.3493\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 8.6817 - acc: 0.4186 - val_loss: 8.9890 - val_acc: 0.5721\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 8.6662 - acc: 0.4503 - val_loss: 3.7241 - val_acc: 0.5939\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 7.9426 - acc: 0.4699 - val_loss: 6.8578 - val_acc: 0.5721\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 10.4590 - acc: 0.4710 - val_loss: 3.1592 - val_acc: 0.3493\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 7.6005 - acc: 0.4721 - val_loss: 2.6954 - val_acc: 0.5764\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 10.2577 - acc: 0.4470 - val_loss: 21.9805 - val_acc: 0.3493\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 10.3451 - acc: 0.4689 - val_loss: 10.2246 - val_acc: 0.5721\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.4462 - acc: 0.5432 - val_loss: 6.8398 - val_acc: 0.5721\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 8.6572 - acc: 0.4317 - val_loss: 12.2832 - val_acc: 0.5721\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.3681 - acc: 0.5202 - val_loss: 7.2725 - val_acc: 0.5721\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.1389 - acc: 0.5005 - val_loss: 17.3281 - val_acc: 0.5721\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.3928 - acc: 0.4776 - val_loss: 6.3697 - val_acc: 0.5721\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 7.9724 - acc: 0.4787 - val_loss: 17.4512 - val_acc: 0.0786\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.9762 - acc: 0.4667 - val_loss: 4.1432 - val_acc: 0.3493\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 7.3570 - acc: 0.4481 - val_loss: 9.8859 - val_acc: 0.5721\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.5922 - acc: 0.4448 - val_loss: 13.8595 - val_acc: 0.3493\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 7.0451 - acc: 0.5290 - val_loss: 8.1367 - val_acc: 0.5721\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 8.1840 - acc: 0.4612 - val_loss: 3.9099 - val_acc: 0.3493\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 6.1001 - acc: 0.4765 - val_loss: 5.7556 - val_acc: 0.3493\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.1783 - acc: 0.5049 - val_loss: 2.6366 - val_acc: 0.2489\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 5.6313 - acc: 0.4995 - val_loss: 4.7398 - val_acc: 0.0786\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.8780 - acc: 0.4973 - val_loss: 16.2310 - val_acc: 0.5721\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 8.3141 - acc: 0.4404 - val_loss: 3.9125 - val_acc: 0.4629\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.8444 - acc: 0.5038 - val_loss: 1.7710 - val_acc: 0.5852\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 6.9358 - acc: 0.4678 - val_loss: 9.2020 - val_acc: 0.3493\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.0613 - acc: 0.4339 - val_loss: 12.6438 - val_acc: 0.5721\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.9859 - acc: 0.5956 - val_loss: 7.8235 - val_acc: 0.5721\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 9.7152 - acc: 0.4284 - val_loss: 2.9534 - val_acc: 0.4017\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.4867 - acc: 0.5628 - val_loss: 2.3777 - val_acc: 0.3144\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 4.4372 - acc: 0.5956 - val_loss: 5.6189 - val_acc: 0.5852\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.8915 - acc: 0.4546 - val_loss: 7.6648 - val_acc: 0.3493\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.6890 - acc: 0.4634 - val_loss: 9.3313 - val_acc: 0.3493\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 8.3738 - acc: 0.5016 - val_loss: 8.4436 - val_acc: 0.3493\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.9098 - acc: 0.4481 - val_loss: 4.2265 - val_acc: 0.5721\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 7.4894 - acc: 0.5027 - val_loss: 4.7548 - val_acc: 0.5459\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 7.6947 - acc: 0.5355 - val_loss: 13.4459 - val_acc: 0.5721\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 8.2292 - acc: 0.4612 - val_loss: 5.3982 - val_acc: 0.3493\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.7371 - acc: 0.4831 - val_loss: 5.6833 - val_acc: 0.5721\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 6.8312 - acc: 0.5279 - val_loss: 11.1471 - val_acc: 0.5721\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 6.9746 - acc: 0.4984 - val_loss: 10.3436 - val_acc: 0.5721\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 6.8433 - acc: 0.4546 - val_loss: 5.4702 - val_acc: 0.3493\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.3757 - acc: 0.5607 - val_loss: 1.1394 - val_acc: 0.5721\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 6.6324 - acc: 0.5115 - val_loss: 11.4877 - val_acc: 0.5721\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.4042 - acc: 0.4863 - val_loss: 2.9161 - val_acc: 0.6157\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 6.6113 - acc: 0.4579 - val_loss: 10.4530 - val_acc: 0.3493\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 7.2373 - acc: 0.5169 - val_loss: 1.2275 - val_acc: 0.5983\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 6.4229 - acc: 0.4820 - val_loss: 6.6977 - val_acc: 0.5721\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.1743 - acc: 0.4546 - val_loss: 7.4630 - val_acc: 0.3493\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 7.3226 - acc: 0.4798 - val_loss: 4.1703 - val_acc: 0.5721\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.1006 - acc: 0.6033 - val_loss: 13.1397 - val_acc: 0.0786\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 9.0156 - acc: 0.4732 - val_loss: 15.6998 - val_acc: 0.5721\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 8.8853 - acc: 0.4601 - val_loss: 8.3817 - val_acc: 0.3493\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 5.4350 - acc: 0.5913 - val_loss: 5.9939 - val_acc: 0.5721\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 5.2282 - acc: 0.4929 - val_loss: 9.0207 - val_acc: 0.5721\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 6.8150 - acc: 0.4525 - val_loss: 16.7916 - val_acc: 0.3493\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 9.6177 - acc: 0.4896 - val_loss: 10.8692 - val_acc: 0.5721\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 7.0553 - acc: 0.4732 - val_loss: 7.5085 - val_acc: 0.3493\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.5618 - acc: 0.5169 - val_loss: 6.3954 - val_acc: 0.3493\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.2601 - acc: 0.4689 - val_loss: 2.6609 - val_acc: 0.5808\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 5.9422 - acc: 0.5180 - val_loss: 1.8428 - val_acc: 0.5852\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 7.6124 - acc: 0.4492 - val_loss: 10.4682 - val_acc: 0.3493\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 6.3191 - acc: 0.4579 - val_loss: 10.9980 - val_acc: 0.3493\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.9690 - acc: 0.4918 - val_loss: 6.5606 - val_acc: 0.5721\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 6.2954 - acc: 0.5148 - val_loss: 1.1003 - val_acc: 0.5590\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 6.8928 - acc: 0.4842 - val_loss: 5.3032 - val_acc: 0.5721\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.8693 - acc: 0.5279 - val_loss: 1.7332 - val_acc: 0.3537\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.7861 - acc: 0.5137 - val_loss: 10.1911 - val_acc: 0.5721\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 6.0537 - acc: 0.5301 - val_loss: 10.5040 - val_acc: 0.5721\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 6.8710 - acc: 0.5410 - val_loss: 13.2558 - val_acc: 0.5721\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.1486 - acc: 0.5322 - val_loss: 1.4835 - val_acc: 0.4629\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.5640 - acc: 0.5639 - val_loss: 4.7902 - val_acc: 0.1921\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 8.5489 - acc: 0.4470 - val_loss: 9.6864 - val_acc: 0.5721\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 6.8197 - acc: 0.4820 - val_loss: 5.7451 - val_acc: 0.3493\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 7.2591 - acc: 0.4514 - val_loss: 2.5141 - val_acc: 0.4017\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.0530 - acc: 0.5814 - val_loss: 10.9354 - val_acc: 0.5721\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 6.7810 - acc: 0.5126 - val_loss: 8.8936 - val_acc: 0.5721\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 5.7702 - acc: 0.5464 - val_loss: 5.0192 - val_acc: 0.5721\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.4771 - acc: 0.4284 - val_loss: 11.4376 - val_acc: 0.3493\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 7.1874 - acc: 0.5104 - val_loss: 8.3578 - val_acc: 0.5721\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 5.5622 - acc: 0.4809 - val_loss: 20.2731 - val_acc: 0.3493\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 8.6030 - acc: 0.5071 - val_loss: 6.0361 - val_acc: 0.0786\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 6.0179 - acc: 0.4787 - val_loss: 3.7925 - val_acc: 0.5721\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 4.9960 - acc: 0.4809 - val_loss: 4.1636 - val_acc: 0.3493\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.5965 - acc: 0.4557 - val_loss: 3.3464 - val_acc: 0.3930\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 4.9839 - acc: 0.5169 - val_loss: 3.2727 - val_acc: 0.4934\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 5.1420 - acc: 0.5989 - val_loss: 9.6351 - val_acc: 0.5721\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 10.1895 - acc: 0.4536 - val_loss: 10.4995 - val_acc: 0.3493\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.3450 - acc: 0.4448 - val_loss: 1.5227 - val_acc: 0.4629\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.4187 - acc: 0.5464 - val_loss: 6.3801 - val_acc: 0.3493\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 5.1345 - acc: 0.5115 - val_loss: 3.3596 - val_acc: 0.5721\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.2736 - acc: 0.4973 - val_loss: 1.4758 - val_acc: 0.4629\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 5.1107 - acc: 0.5191 - val_loss: 10.5613 - val_acc: 0.5721\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 7.0727 - acc: 0.5082 - val_loss: 9.5881 - val_acc: 0.5721\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.1541 - acc: 0.5344 - val_loss: 11.2639 - val_acc: 0.5721\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 6.7567 - acc: 0.4339 - val_loss: 1.8448 - val_acc: 0.6725\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.4855 - acc: 0.5421 - val_loss: 9.9649 - val_acc: 0.5721\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 4.5807 - acc: 0.5355 - val_loss: 7.5661 - val_acc: 0.5721\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.0283 - acc: 0.5355 - val_loss: 5.7913 - val_acc: 0.3493\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.7958 - acc: 0.5104 - val_loss: 9.2407 - val_acc: 0.5721\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.2860 - acc: 0.4361 - val_loss: 8.8685 - val_acc: 0.3493\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 4.9962 - acc: 0.4929 - val_loss: 3.5874 - val_acc: 0.5983\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.8414 - acc: 0.6109 - val_loss: 8.1347 - val_acc: 0.3406\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.1491 - acc: 0.4634 - val_loss: 9.7098 - val_acc: 0.5721\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.0839 - acc: 0.5945 - val_loss: 4.5885 - val_acc: 0.0830\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.7370 - acc: 0.5377 - val_loss: 5.8060 - val_acc: 0.5721\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.2530 - acc: 0.4623 - val_loss: 10.2647 - val_acc: 0.5721\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 5.8936 - acc: 0.5060 - val_loss: 4.1764 - val_acc: 0.5764\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.2722 - acc: 0.5344 - val_loss: 8.9090 - val_acc: 0.5721\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 5.2653 - acc: 0.4710 - val_loss: 4.2740 - val_acc: 0.3493\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.5028 - acc: 0.5705 - val_loss: 5.4406 - val_acc: 0.3493\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.8122 - acc: 0.5454 - val_loss: 10.5105 - val_acc: 0.5721\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 4.6945 - acc: 0.5596 - val_loss: 7.7482 - val_acc: 0.3493\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.9548 - acc: 0.4809 - val_loss: 2.1268 - val_acc: 0.2314\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 4.3599 - acc: 0.4623 - val_loss: 16.5886 - val_acc: 0.0830\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 11.4543 - acc: 0.4219 - val_loss: 8.4076 - val_acc: 0.3493\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 3.7644 - acc: 0.5902 - val_loss: 1.7808 - val_acc: 0.6332\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.7792 - acc: 0.5410 - val_loss: 2.8947 - val_acc: 0.5895\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 3.9969 - acc: 0.5169 - val_loss: 3.3062 - val_acc: 0.6245\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.0991 - acc: 0.5716 - val_loss: 3.6551 - val_acc: 0.5721\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 5.2285 - acc: 0.4820 - val_loss: 3.5225 - val_acc: 0.5721\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 4.3294 - acc: 0.4962 - val_loss: 2.5385 - val_acc: 0.5721\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.5136 - acc: 0.7060 - val_loss: 3.9256 - val_acc: 0.3493\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 4.8278 - acc: 0.4710 - val_loss: 3.7638 - val_acc: 0.3537\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 5.4832 - acc: 0.4393 - val_loss: 5.4919 - val_acc: 0.3493\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 4.4598 - acc: 0.5213 - val_loss: 5.9167 - val_acc: 0.3493\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.2671 - acc: 0.4798 - val_loss: 2.4686 - val_acc: 0.6245\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 4.1749 - acc: 0.5541 - val_loss: 2.9404 - val_acc: 0.5852\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.5982 - acc: 0.5464 - val_loss: 2.9853 - val_acc: 0.3712\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.1523 - acc: 0.5027 - val_loss: 10.9947 - val_acc: 0.5721\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.0995 - acc: 0.5268 - val_loss: 6.2065 - val_acc: 0.5721\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.7311 - acc: 0.4940 - val_loss: 2.0361 - val_acc: 0.5983\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.2942 - acc: 0.5311 - val_loss: 4.0778 - val_acc: 0.3493\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.7739 - acc: 0.5148 - val_loss: 2.3243 - val_acc: 0.5983\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 4.2054 - acc: 0.5126 - val_loss: 11.0184 - val_acc: 0.5721\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 4.8221 - acc: 0.5333 - val_loss: 3.2017 - val_acc: 0.5939\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.0644 - acc: 0.5126 - val_loss: 2.8546 - val_acc: 0.3493\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 4.9117 - acc: 0.4612 - val_loss: 5.5953 - val_acc: 0.2620\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.4871 - acc: 0.4743 - val_loss: 8.6276 - val_acc: 0.5721\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 4.8234 - acc: 0.4689 - val_loss: 2.9651 - val_acc: 0.5721\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.9202 - acc: 0.4929 - val_loss: 9.6619 - val_acc: 0.5721\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.9638 - acc: 0.5432 - val_loss: 8.9116 - val_acc: 0.3493\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.1296 - acc: 0.4109 - val_loss: 1.0593 - val_acc: 0.5983\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 3.8528 - acc: 0.4929 - val_loss: 1.9359 - val_acc: 0.3624\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 3.6830 - acc: 0.4918 - val_loss: 10.2486 - val_acc: 0.5721\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 4.6544 - acc: 0.5279 - val_loss: 2.3137 - val_acc: 0.3712\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 3.3813 - acc: 0.5191 - val_loss: 2.1253 - val_acc: 0.5721\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.9766 - acc: 0.4525 - val_loss: 8.6791 - val_acc: 0.5721\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 4.3561 - acc: 0.4929 - val_loss: 1.3978 - val_acc: 0.5721\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.4357 - acc: 0.4984 - val_loss: 6.6842 - val_acc: 0.5721\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.9394 - acc: 0.6262 - val_loss: 4.8717 - val_acc: 0.5721\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 5.0713 - acc: 0.4590 - val_loss: 5.4828 - val_acc: 0.5721\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.9090 - acc: 0.5104 - val_loss: 4.7313 - val_acc: 0.5721\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 3.6605 - acc: 0.4590 - val_loss: 6.7994 - val_acc: 0.5721\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.4794 - acc: 0.5574 - val_loss: 2.8139 - val_acc: 0.5721\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.6810 - acc: 0.4536 - val_loss: 2.6901 - val_acc: 0.3493\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.8763 - acc: 0.4306 - val_loss: 5.2800 - val_acc: 0.5721\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.0637 - acc: 0.4984 - val_loss: 2.0177 - val_acc: 0.5808\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.7198 - acc: 0.4940 - val_loss: 6.5042 - val_acc: 0.5721\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.6145 - acc: 0.5082 - val_loss: 1.4132 - val_acc: 0.6070\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 3.8946 - acc: 0.4776 - val_loss: 1.1405 - val_acc: 0.6201\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.8898 - acc: 0.4918 - val_loss: 5.0458 - val_acc: 0.3493\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 3.9583 - acc: 0.5355 - val_loss: 3.6741 - val_acc: 0.0830\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.1759 - acc: 0.4601 - val_loss: 7.0939 - val_acc: 0.5721\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.9707 - acc: 0.5607 - val_loss: 3.6542 - val_acc: 0.3493\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 3.1863 - acc: 0.5694 - val_loss: 5.7079 - val_acc: 0.5721\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.5624 - acc: 0.5672 - val_loss: 3.8956 - val_acc: 0.3493\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 3.7353 - acc: 0.5126 - val_loss: 4.8865 - val_acc: 0.5721\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 3.5803 - acc: 0.5082 - val_loss: 6.5425 - val_acc: 0.3493\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.7790 - acc: 0.5443 - val_loss: 7.4272 - val_acc: 0.0786\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 5.4513 - acc: 0.4536 - val_loss: 1.2743 - val_acc: 0.3974\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.1101 - acc: 0.4459 - val_loss: 0.8078 - val_acc: 0.5852\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.5734 - acc: 0.5421 - val_loss: 2.6228 - val_acc: 0.3493\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 2.9550 - acc: 0.5410 - val_loss: 4.2357 - val_acc: 0.5721\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.9784 - acc: 0.5148 - val_loss: 4.4252 - val_acc: 0.3493\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.2937 - acc: 0.4579 - val_loss: 10.1980 - val_acc: 0.5721\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 4.7300 - acc: 0.4645 - val_loss: 7.6452 - val_acc: 0.3493\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 4.3435 - acc: 0.5104 - val_loss: 2.4136 - val_acc: 0.3450\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.1634 - acc: 0.5760 - val_loss: 4.8499 - val_acc: 0.5721\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.7661 - acc: 0.4448 - val_loss: 4.4160 - val_acc: 0.3493\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 2.4879 - acc: 0.5399 - val_loss: 3.2467 - val_acc: 0.3493\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.1449 - acc: 0.5169 - val_loss: 7.3873 - val_acc: 0.5721\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 3.7059 - acc: 0.4787 - val_loss: 1.0155 - val_acc: 0.5459\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.2966 - acc: 0.5464 - val_loss: 5.5279 - val_acc: 0.3493\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.8743 - acc: 0.5464 - val_loss: 5.5005 - val_acc: 0.5721\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.6098 - acc: 0.6077 - val_loss: 4.3395 - val_acc: 0.5721\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.9185 - acc: 0.4656 - val_loss: 5.5638 - val_acc: 0.5721\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.8492 - acc: 0.5836 - val_loss: 7.0983 - val_acc: 0.3493\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 4.1091 - acc: 0.4459 - val_loss: 6.2483 - val_acc: 0.3493\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 3.4026 - acc: 0.4787 - val_loss: 3.7764 - val_acc: 0.5721\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.5654 - acc: 0.4295 - val_loss: 6.3328 - val_acc: 0.5721\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.7898 - acc: 0.5454 - val_loss: 1.4693 - val_acc: 0.3581\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.9179 - acc: 0.4951 - val_loss: 2.4021 - val_acc: 0.3493\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.5117 - acc: 0.5585 - val_loss: 3.0440 - val_acc: 0.5721\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 3.3751 - acc: 0.4579 - val_loss: 0.7692 - val_acc: 0.6376\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.9000 - acc: 0.5104 - val_loss: 4.3375 - val_acc: 0.5721\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.7473 - acc: 0.4743 - val_loss: 4.8018 - val_acc: 0.3493\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 3.0183 - acc: 0.4798 - val_loss: 5.2403 - val_acc: 0.3493\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.2936 - acc: 0.4798 - val_loss: 8.5827 - val_acc: 0.3493\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 3.3247 - acc: 0.4667 - val_loss: 4.5719 - val_acc: 0.3493\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.3267 - acc: 0.5399 - val_loss: 1.4627 - val_acc: 0.5197\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.1813 - acc: 0.5421 - val_loss: 3.1857 - val_acc: 0.3493\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.8117 - acc: 0.4874 - val_loss: 8.9703 - val_acc: 0.3493\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 6.2587 - acc: 0.4863 - val_loss: 5.4415 - val_acc: 0.5721\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.8771 - acc: 0.4765 - val_loss: 3.8923 - val_acc: 0.5721\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.6692 - acc: 0.4798 - val_loss: 2.6878 - val_acc: 0.5721\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.0825 - acc: 0.5399 - val_loss: 2.5927 - val_acc: 0.5721\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.0716 - acc: 0.5683 - val_loss: 4.6763 - val_acc: 0.3493\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.3355 - acc: 0.4546 - val_loss: 1.6667 - val_acc: 0.4148\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.6090 - acc: 0.5093 - val_loss: 6.3823 - val_acc: 0.3493\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.2776 - acc: 0.5344 - val_loss: 0.9471 - val_acc: 0.5939\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.7947 - acc: 0.4645 - val_loss: 5.8489 - val_acc: 0.5721\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.8930 - acc: 0.5158 - val_loss: 4.9838 - val_acc: 0.5721\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 3.1348 - acc: 0.4754 - val_loss: 0.8918 - val_acc: 0.5939\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.8440 - acc: 0.5727 - val_loss: 1.6691 - val_acc: 0.3668\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 2.8523 - acc: 0.4536 - val_loss: 1.7555 - val_acc: 0.3843\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.1249 - acc: 0.5191 - val_loss: 2.4296 - val_acc: 0.3493\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.4376 - acc: 0.5541 - val_loss: 3.3784 - val_acc: 0.5895\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.5162 - acc: 0.5497 - val_loss: 4.8490 - val_acc: 0.5764\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 2.5667 - acc: 0.5574 - val_loss: 5.6757 - val_acc: 0.0786\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.0026 - acc: 0.4984 - val_loss: 0.8666 - val_acc: 0.5633\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.8488 - acc: 0.4732 - val_loss: 1.9481 - val_acc: 0.4017\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.0577 - acc: 0.5421 - val_loss: 3.3338 - val_acc: 0.2358\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.7498 - acc: 0.5016 - val_loss: 3.3776 - val_acc: 0.3493\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.2566 - acc: 0.5322 - val_loss: 1.6834 - val_acc: 0.6288\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.5061 - acc: 0.5596 - val_loss: 10.6520 - val_acc: 0.5721\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.8360 - acc: 0.5180 - val_loss: 0.9715 - val_acc: 0.6114\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.6719 - acc: 0.5410 - val_loss: 1.0982 - val_acc: 0.4454\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.7370 - acc: 0.4546 - val_loss: 2.8587 - val_acc: 0.3581\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.0120 - acc: 0.5792 - val_loss: 4.1643 - val_acc: 0.5721\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.1716 - acc: 0.5902 - val_loss: 1.0595 - val_acc: 0.5066\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.6146 - acc: 0.4984 - val_loss: 2.2339 - val_acc: 0.3537\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.0386 - acc: 0.4131 - val_loss: 1.4253 - val_acc: 0.5895\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 2.1102 - acc: 0.5322 - val_loss: 1.8408 - val_acc: 0.5721\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.2111 - acc: 0.5126 - val_loss: 2.4346 - val_acc: 0.3493\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 4.0225 - acc: 0.4743 - val_loss: 2.0258 - val_acc: 0.3886\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.6683 - acc: 0.5694 - val_loss: 5.0625 - val_acc: 0.3493\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.2626 - acc: 0.5825 - val_loss: 2.3758 - val_acc: 0.3275\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.1160 - acc: 0.4492 - val_loss: 1.3004 - val_acc: 0.4236\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.4814 - acc: 0.4907 - val_loss: 7.2544 - val_acc: 0.0786\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 7.1253 - acc: 0.3956 - val_loss: 3.1850 - val_acc: 0.1878\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.1904 - acc: 0.5005 - val_loss: 1.2018 - val_acc: 0.5983\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.0507 - acc: 0.5574 - val_loss: 1.4513 - val_acc: 0.5895\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.0159 - acc: 0.5049 - val_loss: 3.4107 - val_acc: 0.5721\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.0126 - acc: 0.5683 - val_loss: 1.4479 - val_acc: 0.6026\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.2729 - acc: 0.5246 - val_loss: 0.7647 - val_acc: 0.6332\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.6071 - acc: 0.5781 - val_loss: 5.0754 - val_acc: 0.5721\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.6093 - acc: 0.4656 - val_loss: 1.8792 - val_acc: 0.6026\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.8566 - acc: 0.5530 - val_loss: 4.3377 - val_acc: 0.5721\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.0118 - acc: 0.5268 - val_loss: 2.6465 - val_acc: 0.3493\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.7146 - acc: 0.5355 - val_loss: 3.7126 - val_acc: 0.3493\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.0796 - acc: 0.5792 - val_loss: 2.0512 - val_acc: 0.5852\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.1682 - acc: 0.5355 - val_loss: 2.5132 - val_acc: 0.5721\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.5331 - acc: 0.5005 - val_loss: 2.3228 - val_acc: 0.5721\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.9532 - acc: 0.5137 - val_loss: 1.3291 - val_acc: 0.5895\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.0755 - acc: 0.5148 - val_loss: 0.8078 - val_acc: 0.6201\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2885 - acc: 0.6546 - val_loss: 4.1709 - val_acc: 0.5721\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.6898 - acc: 0.6153 - val_loss: 3.2047 - val_acc: 0.3493\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.6082 - acc: 0.6601 - val_loss: 3.0382 - val_acc: 0.5721\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.1375 - acc: 0.4262 - val_loss: 5.9958 - val_acc: 0.5721\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.2874 - acc: 0.5770 - val_loss: 1.2582 - val_acc: 0.4105\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.9371 - acc: 0.5005 - val_loss: 1.5725 - val_acc: 0.3537\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.9045 - acc: 0.5585 - val_loss: 1.6650 - val_acc: 0.5852\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.8377 - acc: 0.4995 - val_loss: 1.9991 - val_acc: 0.3537\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.8447 - acc: 0.5454 - val_loss: 4.0686 - val_acc: 0.3493\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.9745 - acc: 0.4984 - val_loss: 2.7255 - val_acc: 0.3493\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.2720 - acc: 0.5213 - val_loss: 3.6925 - val_acc: 0.5721\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 6.2523 - acc: 0.4667 - val_loss: 5.5442 - val_acc: 0.5721\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 2.0900 - acc: 0.5803 - val_loss: 1.0942 - val_acc: 0.4192\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.0775 - acc: 0.4918 - val_loss: 1.2055 - val_acc: 0.3668\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.4335 - acc: 0.5760 - val_loss: 1.0059 - val_acc: 0.4498\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.4100 - acc: 0.6230 - val_loss: 3.4129 - val_acc: 0.5371\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.4771 - acc: 0.4929 - val_loss: 8.1307 - val_acc: 0.5721\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.9047 - acc: 0.5781 - val_loss: 1.9919 - val_acc: 0.3493\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.3507 - acc: 0.5574 - val_loss: 1.1468 - val_acc: 0.3712\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.3032 - acc: 0.5148 - val_loss: 1.8237 - val_acc: 0.3668\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.7209 - acc: 0.5115 - val_loss: 6.9337 - val_acc: 0.0786\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.6341 - acc: 0.4448 - val_loss: 1.4764 - val_acc: 0.5721\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.0931 - acc: 0.5290 - val_loss: 1.0954 - val_acc: 0.5808\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.3353 - acc: 0.5279 - val_loss: 0.7789 - val_acc: 0.5983\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.3485 - acc: 0.5071 - val_loss: 1.1612 - val_acc: 0.3362\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.3945 - acc: 0.5410 - val_loss: 1.1849 - val_acc: 0.5721\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.0853 - acc: 0.6918 - val_loss: 1.9030 - val_acc: 0.5852\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.0582 - acc: 0.5213 - val_loss: 1.6825 - val_acc: 0.5721\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1723 - acc: 0.6197 - val_loss: 5.9071 - val_acc: 0.0786\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 2.6881 - acc: 0.4820 - val_loss: 2.4902 - val_acc: 0.5808\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.4196 - acc: 0.5792 - val_loss: 2.7214 - val_acc: 0.5721\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.0599 - acc: 0.4754 - val_loss: 1.2977 - val_acc: 0.3493\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.7261 - acc: 0.4852 - val_loss: 1.6964 - val_acc: 0.5721\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.4607 - acc: 0.5585 - val_loss: 1.4035 - val_acc: 0.3537\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.2344 - acc: 0.5169 - val_loss: 0.8674 - val_acc: 0.5808\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.2789 - acc: 0.5115 - val_loss: 2.2549 - val_acc: 0.3493\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.0181 - acc: 0.5388 - val_loss: 1.1964 - val_acc: 0.3581\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1572 - acc: 0.5607 - val_loss: 1.2781 - val_acc: 0.5895\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.5365 - acc: 0.5432 - val_loss: 4.9751 - val_acc: 0.5808\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.7099 - acc: 0.5672 - val_loss: 1.1949 - val_acc: 0.3581\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.3351 - acc: 0.5781 - val_loss: 1.8270 - val_acc: 0.3537\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2720 - acc: 0.5301 - val_loss: 9.2614 - val_acc: 0.0786\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.6637 - acc: 0.5388 - val_loss: 1.8587 - val_acc: 0.5764\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.1214 - acc: 0.6415 - val_loss: 0.8919 - val_acc: 0.4105\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.3939 - acc: 0.5005 - val_loss: 0.9133 - val_acc: 0.5983\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1855 - acc: 0.5596 - val_loss: 2.9360 - val_acc: 0.5721\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.5577 - acc: 0.4984 - val_loss: 1.3655 - val_acc: 0.5939\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.3880 - acc: 0.5749 - val_loss: 2.7853 - val_acc: 0.5808\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.2021 - acc: 0.6011 - val_loss: 2.6647 - val_acc: 0.1223\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.2051 - acc: 0.4437 - val_loss: 2.4712 - val_acc: 0.5852\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.6316 - acc: 0.5945 - val_loss: 2.0981 - val_acc: 0.5721\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2157 - acc: 0.5464 - val_loss: 1.2636 - val_acc: 0.3581\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.4501 - acc: 0.5202 - val_loss: 0.7466 - val_acc: 0.6376\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2828 - acc: 0.5333 - val_loss: 2.2014 - val_acc: 0.5721\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.5234 - acc: 0.5552 - val_loss: 1.5170 - val_acc: 0.3493\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.2757 - acc: 0.5180 - val_loss: 2.7469 - val_acc: 0.5721\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.3328 - acc: 0.5967 - val_loss: 1.5746 - val_acc: 0.5939\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.1784 - acc: 0.6066 - val_loss: 0.7439 - val_acc: 0.6550\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.0736 - acc: 0.5814 - val_loss: 2.8356 - val_acc: 0.3493\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 3.8657 - acc: 0.4426 - val_loss: 1.0203 - val_acc: 0.6419\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9681 - acc: 0.5945 - val_loss: 1.9392 - val_acc: 0.5939\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.2362 - acc: 0.5672 - val_loss: 2.9998 - val_acc: 0.5721\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2157 - acc: 0.5738 - val_loss: 1.2541 - val_acc: 0.5677\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.0399 - acc: 0.5770 - val_loss: 0.7481 - val_acc: 0.6594\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.0307 - acc: 0.6186 - val_loss: 5.3035 - val_acc: 0.0786\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 2.5126 - acc: 0.4164 - val_loss: 0.9460 - val_acc: 0.5371\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9185 - acc: 0.6120 - val_loss: 2.7660 - val_acc: 0.5764\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.4774 - acc: 0.5443 - val_loss: 3.3550 - val_acc: 0.3493\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.5483 - acc: 0.5388 - val_loss: 3.0766 - val_acc: 0.5721\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.5154 - acc: 0.5180 - val_loss: 1.4225 - val_acc: 0.5764\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.6305 - acc: 0.5421 - val_loss: 1.0296 - val_acc: 0.4017\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.0974 - acc: 0.5148 - val_loss: 0.8850 - val_acc: 0.6157\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.6931 - acc: 0.7749 - val_loss: 0.9406 - val_acc: 0.6070\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2332 - acc: 0.6645 - val_loss: 0.9151 - val_acc: 0.6376\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.2420 - acc: 0.6186 - val_loss: 1.2483 - val_acc: 0.5153\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1689 - acc: 0.5967 - val_loss: 1.0696 - val_acc: 0.3974\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.6977 - acc: 0.5115 - val_loss: 1.3434 - val_acc: 0.3537\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9596 - acc: 0.5639 - val_loss: 1.4443 - val_acc: 0.5721\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.0165 - acc: 0.5749 - val_loss: 0.8767 - val_acc: 0.4367\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.0030 - acc: 0.5716 - val_loss: 1.5557 - val_acc: 0.5546\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1980 - acc: 0.5421 - val_loss: 2.4770 - val_acc: 0.3493\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 2.0446 - acc: 0.5333 - val_loss: 1.8405 - val_acc: 0.3493\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 0.9298 - acc: 0.6230 - val_loss: 1.4304 - val_acc: 0.5808\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8377 - acc: 0.6525 - val_loss: 1.9322 - val_acc: 0.5808\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.8072 - acc: 0.6798 - val_loss: 1.7619 - val_acc: 0.5721\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 2.5925 - acc: 0.4623 - val_loss: 0.8348 - val_acc: 0.6026\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.9721 - acc: 0.6000 - val_loss: 0.9621 - val_acc: 0.5983\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.1861 - acc: 0.5825 - val_loss: 2.2340 - val_acc: 0.3493\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1371 - acc: 0.5596 - val_loss: 1.2314 - val_acc: 0.5808\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1379 - acc: 0.5180 - val_loss: 0.8710 - val_acc: 0.5983\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.0367 - acc: 0.5880 - val_loss: 1.0421 - val_acc: 0.6463\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.9506 - acc: 0.6328 - val_loss: 3.5081 - val_acc: 0.3493\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.2241 - acc: 0.6350 - val_loss: 2.1022 - val_acc: 0.3493\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2391 - acc: 0.5355 - val_loss: 1.2190 - val_acc: 0.3974\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1300 - acc: 0.6011 - val_loss: 0.7892 - val_acc: 0.5415\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9487 - acc: 0.6000 - val_loss: 3.1714 - val_acc: 0.3493\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.9543 - acc: 0.4831 - val_loss: 0.9302 - val_acc: 0.5939\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1249 - acc: 0.6339 - val_loss: 1.1830 - val_acc: 0.3974\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7087 - acc: 0.6503 - val_loss: 0.8769 - val_acc: 0.5371\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.9545 - acc: 0.5945 - val_loss: 1.4188 - val_acc: 0.5983\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.1455 - acc: 0.5716 - val_loss: 0.8706 - val_acc: 0.5939\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9392 - acc: 0.6404 - val_loss: 2.3046 - val_acc: 0.5721\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.8879 - acc: 0.4852 - val_loss: 0.8460 - val_acc: 0.6594\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9367 - acc: 0.6995 - val_loss: 3.5680 - val_acc: 0.4629\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.2981 - acc: 0.6131 - val_loss: 0.9324 - val_acc: 0.4367\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7462 - acc: 0.5989 - val_loss: 1.0156 - val_acc: 0.4061\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7862 - acc: 0.6284 - val_loss: 1.4101 - val_acc: 0.4061\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.0716 - acc: 0.5661 - val_loss: 1.6458 - val_acc: 0.5983\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.4742 - acc: 0.5268 - val_loss: 3.5142 - val_acc: 0.0961\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.6850 - acc: 0.5989 - val_loss: 1.3176 - val_acc: 0.5808\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7451 - acc: 0.6383 - val_loss: 1.4755 - val_acc: 0.5808\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.0943 - acc: 0.5978 - val_loss: 0.9556 - val_acc: 0.6594\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.7323 - acc: 0.5191 - val_loss: 0.8952 - val_acc: 0.6638\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8947 - acc: 0.6361 - val_loss: 1.3575 - val_acc: 0.6288\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0217 - acc: 0.6164 - val_loss: 0.9399 - val_acc: 0.5022\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0779 - acc: 0.6284 - val_loss: 1.0157 - val_acc: 0.5808\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.9366 - acc: 0.6262 - val_loss: 6.4124 - val_acc: 0.5721\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.4118 - acc: 0.5880 - val_loss: 1.8407 - val_acc: 0.5764\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7632 - acc: 0.7301 - val_loss: 0.7714 - val_acc: 0.6769\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.0735 - acc: 0.6131 - val_loss: 1.6481 - val_acc: 0.3493\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7947 - acc: 0.6951 - val_loss: 0.7903 - val_acc: 0.6114\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.9602 - acc: 0.6066 - val_loss: 2.8555 - val_acc: 0.5721\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.2062 - acc: 0.5005 - val_loss: 1.9759 - val_acc: 0.6463\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2146 - acc: 0.6098 - val_loss: 0.7137 - val_acc: 0.6245\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6014 - acc: 0.7333 - val_loss: 1.4000 - val_acc: 0.4279\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.9929 - acc: 0.5825 - val_loss: 0.8211 - val_acc: 0.5153\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.8422 - acc: 0.6743 - val_loss: 2.0759 - val_acc: 0.4541\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0767 - acc: 0.6393 - val_loss: 1.9676 - val_acc: 0.3493\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0083 - acc: 0.6448 - val_loss: 4.5853 - val_acc: 0.1092\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.2605 - acc: 0.4678 - val_loss: 1.1189 - val_acc: 0.5022\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5673 - acc: 0.7016 - val_loss: 1.2489 - val_acc: 0.3843\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6930 - acc: 0.6525 - val_loss: 1.0196 - val_acc: 0.4279\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.0286 - acc: 0.5858 - val_loss: 1.2636 - val_acc: 0.6769\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.7389 - acc: 0.6689 - val_loss: 1.0388 - val_acc: 0.5808\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.3948 - acc: 0.5497 - val_loss: 1.0952 - val_acc: 0.5066\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.9451 - acc: 0.6678 - val_loss: 1.0413 - val_acc: 0.5895\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0379 - acc: 0.6066 - val_loss: 1.2883 - val_acc: 0.5808\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.2313 - acc: 0.5563 - val_loss: 1.5306 - val_acc: 0.3493\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.8810 - acc: 0.5694 - val_loss: 1.0747 - val_acc: 0.3843\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.8441 - acc: 0.6044 - val_loss: 1.3404 - val_acc: 0.3843\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1231 - acc: 0.5945 - val_loss: 1.0325 - val_acc: 0.5895\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2755 - acc: 0.5672 - val_loss: 2.0685 - val_acc: 0.3537\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.1203 - acc: 0.5694 - val_loss: 1.1451 - val_acc: 0.3843\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7984 - acc: 0.6470 - val_loss: 1.7449 - val_acc: 0.3581\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7565 - acc: 0.6492 - val_loss: 2.6625 - val_acc: 0.3581\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1619 - acc: 0.5902 - val_loss: 0.6988 - val_acc: 0.6856\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9578 - acc: 0.6601 - val_loss: 6.1653 - val_acc: 0.3493\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 3.7840 - acc: 0.5268 - val_loss: 2.3377 - val_acc: 0.4017\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.0887 - acc: 0.6579 - val_loss: 0.8050 - val_acc: 0.6026\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.8121 - acc: 0.5989 - val_loss: 0.9484 - val_acc: 0.4279\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.7161 - acc: 0.6448 - val_loss: 1.1237 - val_acc: 0.5546\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0287 - acc: 0.5530 - val_loss: 1.6328 - val_acc: 0.5721\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.4734 - acc: 0.4623 - val_loss: 1.5396 - val_acc: 0.6288\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.5103 - acc: 0.8678 - val_loss: 1.6792 - val_acc: 0.5895\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.1595 - acc: 0.5650 - val_loss: 1.1636 - val_acc: 0.5808\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.0020 - acc: 0.5902 - val_loss: 1.5444 - val_acc: 0.5808\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.1371 - acc: 0.5661 - val_loss: 1.4285 - val_acc: 0.5808\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.8693 - acc: 0.6055 - val_loss: 1.0665 - val_acc: 0.5939\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.0491 - acc: 0.5760 - val_loss: 8.4945 - val_acc: 0.0786\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.1834 - acc: 0.4852 - val_loss: 0.7345 - val_acc: 0.6419\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5965 - acc: 0.7257 - val_loss: 0.9002 - val_acc: 0.5240\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7605 - acc: 0.6689 - val_loss: 1.9710 - val_acc: 0.5721\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1940 - acc: 0.6197 - val_loss: 6.0705 - val_acc: 0.0830\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 2.5755 - acc: 0.4776 - val_loss: 1.0383 - val_acc: 0.6157\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.3673 - acc: 0.6033 - val_loss: 0.7948 - val_acc: 0.6463\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9676 - acc: 0.6393 - val_loss: 2.3313 - val_acc: 0.5764\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.5189 - acc: 0.5585 - val_loss: 1.3363 - val_acc: 0.5983\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.1543 - acc: 0.5891 - val_loss: 0.9177 - val_acc: 0.5590\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0928 - acc: 0.5891 - val_loss: 0.7715 - val_acc: 0.6550\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.8722 - acc: 0.6765 - val_loss: 1.5180 - val_acc: 0.4323\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 1.1714 - acc: 0.6339 - val_loss: 1.3169 - val_acc: 0.4891\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.4811 - acc: 0.5967 - val_loss: 2.1212 - val_acc: 0.5808\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0078 - acc: 0.5760 - val_loss: 1.3270 - val_acc: 0.3581\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 4.1028 - acc: 0.5224 - val_loss: 3.0930 - val_acc: 0.3493\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.8475 - acc: 0.6175 - val_loss: 3.3250 - val_acc: 0.1965\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.4265 - acc: 0.5104 - val_loss: 1.4273 - val_acc: 0.5983\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.3025 - acc: 0.6186 - val_loss: 1.3660 - val_acc: 0.6026\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9144 - acc: 0.7301 - val_loss: 1.2741 - val_acc: 0.5764\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4977 - acc: 0.7803 - val_loss: 1.0509 - val_acc: 0.5153\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7220 - acc: 0.7180 - val_loss: 1.2804 - val_acc: 0.5983\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.8337 - acc: 0.6383 - val_loss: 1.6833 - val_acc: 0.5808\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.2113 - acc: 0.6230 - val_loss: 0.9430 - val_acc: 0.6026\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7960 - acc: 0.6459 - val_loss: 1.7096 - val_acc: 0.5240\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.9619 - acc: 0.5902 - val_loss: 1.6273 - val_acc: 0.5764\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8793 - acc: 0.6557 - val_loss: 1.0876 - val_acc: 0.5852\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7707 - acc: 0.6098 - val_loss: 1.2341 - val_acc: 0.5764\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0855 - acc: 0.5541 - val_loss: 1.5614 - val_acc: 0.3581\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6818 - acc: 0.6415 - val_loss: 1.0411 - val_acc: 0.5895\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7884 - acc: 0.6240 - val_loss: 0.6896 - val_acc: 0.6812\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6317 - acc: 0.7060 - val_loss: 1.6535 - val_acc: 0.3843\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.9374 - acc: 0.5825 - val_loss: 2.4331 - val_acc: 0.3537\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8798 - acc: 0.6208 - val_loss: 1.1613 - val_acc: 0.4061\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.5846 - acc: 0.6689 - val_loss: 0.8493 - val_acc: 0.5240\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.6707 - acc: 0.6525 - val_loss: 0.8560 - val_acc: 0.6157\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.1257 - acc: 0.6033 - val_loss: 0.8085 - val_acc: 0.6769\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6220 - acc: 0.7923 - val_loss: 0.7843 - val_acc: 0.6288\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9378 - acc: 0.6372 - val_loss: 1.2512 - val_acc: 0.5808\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.8574 - acc: 0.6350 - val_loss: 2.1013 - val_acc: 0.5808\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7896 - acc: 0.7563 - val_loss: 1.5204 - val_acc: 0.6245\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.9026 - acc: 0.6339 - val_loss: 1.4631 - val_acc: 0.5895\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.8121 - acc: 0.6721 - val_loss: 1.6672 - val_acc: 0.5808\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.2480 - acc: 0.5902 - val_loss: 1.4184 - val_acc: 0.5633\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.7046 - acc: 0.6437 - val_loss: 1.3849 - val_acc: 0.3624\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6553 - acc: 0.6557 - val_loss: 1.8316 - val_acc: 0.3537\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0918 - acc: 0.5770 - val_loss: 0.8562 - val_acc: 0.5415\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4515 - acc: 0.8328 - val_loss: 1.7279 - val_acc: 0.5808\n",
            "Epoch 701/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7276 - acc: 0.6885 - val_loss: 1.0192 - val_acc: 0.5895\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7963 - acc: 0.6295 - val_loss: 0.8364 - val_acc: 0.5415\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6497 - acc: 0.6852 - val_loss: 2.3622 - val_acc: 0.2009\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.8172 - acc: 0.5333 - val_loss: 0.7205 - val_acc: 0.6725\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.4191 - acc: 0.8186 - val_loss: 0.8546 - val_acc: 0.5721\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.8052 - acc: 0.6197 - val_loss: 1.0924 - val_acc: 0.6201\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6212 - acc: 0.7377 - val_loss: 0.7880 - val_acc: 0.6245\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6157 - acc: 0.6907 - val_loss: 1.5501 - val_acc: 0.5939\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9396 - acc: 0.6437 - val_loss: 2.7132 - val_acc: 0.3231\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.3367 - acc: 0.5344 - val_loss: 1.4190 - val_acc: 0.3843\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.5770 - acc: 0.6852 - val_loss: 1.0341 - val_acc: 0.4105\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6140 - acc: 0.6776 - val_loss: 1.4885 - val_acc: 0.3581\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7756 - acc: 0.6350 - val_loss: 0.7907 - val_acc: 0.6070\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.6916 - acc: 0.6579 - val_loss: 1.0055 - val_acc: 0.5022\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9446 - acc: 0.6011 - val_loss: 1.5084 - val_acc: 0.5895\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 2.8071 - acc: 0.5180 - val_loss: 0.8957 - val_acc: 0.6026\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4543 - acc: 0.8109 - val_loss: 1.0046 - val_acc: 0.6026\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.8948 - acc: 0.6404 - val_loss: 1.2392 - val_acc: 0.5808\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.8504 - acc: 0.6710 - val_loss: 2.4795 - val_acc: 0.5983\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.4001 - acc: 0.5836 - val_loss: 0.8488 - val_acc: 0.6245\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6846 - acc: 0.7137 - val_loss: 1.0009 - val_acc: 0.6114\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0200 - acc: 0.5847 - val_loss: 1.0991 - val_acc: 0.4148\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.7940 - acc: 0.6109 - val_loss: 0.9820 - val_acc: 0.4236\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.7988 - acc: 0.6164 - val_loss: 1.4786 - val_acc: 0.5808\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1087 - acc: 0.6273 - val_loss: 0.9652 - val_acc: 0.4498\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.6203 - acc: 0.6634 - val_loss: 0.7627 - val_acc: 0.6812\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6878 - acc: 0.7454 - val_loss: 1.2500 - val_acc: 0.5109\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8379 - acc: 0.6262 - val_loss: 0.7187 - val_acc: 0.6943\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.4125 - acc: 0.8470 - val_loss: 1.3898 - val_acc: 0.4454\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.5529 - acc: 0.5716 - val_loss: 0.7742 - val_acc: 0.6769\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.4881 - acc: 0.7727 - val_loss: 0.9353 - val_acc: 0.6070\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8459 - acc: 0.6328 - val_loss: 1.8009 - val_acc: 0.5808\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.4825 - acc: 0.8699 - val_loss: 1.3963 - val_acc: 0.5808\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8184 - acc: 0.6699 - val_loss: 1.4088 - val_acc: 0.5808\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.8662 - acc: 0.6230 - val_loss: 1.2296 - val_acc: 0.6026\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.6976 - acc: 0.6350 - val_loss: 0.7730 - val_acc: 0.6550\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.5836 - acc: 0.7628 - val_loss: 1.1538 - val_acc: 0.5939\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1621 - acc: 0.5945 - val_loss: 2.5832 - val_acc: 0.5721\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9025 - acc: 0.6284 - val_loss: 1.9036 - val_acc: 0.5895\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8067 - acc: 0.6339 - val_loss: 0.9668 - val_acc: 0.5721\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5365 - acc: 0.7038 - val_loss: 0.7653 - val_acc: 0.6812\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5935 - acc: 0.6984 - val_loss: 1.2710 - val_acc: 0.4367\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1460 - acc: 0.5639 - val_loss: 0.9301 - val_acc: 0.5983\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.6440 - acc: 0.6689 - val_loss: 0.9072 - val_acc: 0.5764\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.8488 - acc: 0.7005 - val_loss: 1.8813 - val_acc: 0.5939\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6548 - acc: 0.7027 - val_loss: 1.4807 - val_acc: 0.5808\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8142 - acc: 0.6066 - val_loss: 1.4364 - val_acc: 0.5983\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.8367 - acc: 0.6197 - val_loss: 1.9189 - val_acc: 0.4017\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.1411 - acc: 0.6448 - val_loss: 1.3479 - val_acc: 0.3930\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.6309 - acc: 0.6754 - val_loss: 0.9448 - val_acc: 0.5284\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0368 - acc: 0.6918 - val_loss: 0.8812 - val_acc: 0.5983\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.4901 - acc: 0.7574 - val_loss: 1.7053 - val_acc: 0.6507\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7933 - acc: 0.6940 - val_loss: 1.2844 - val_acc: 0.5808\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6374 - acc: 0.6754 - val_loss: 0.7477 - val_acc: 0.6943\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.6468 - acc: 0.7202 - val_loss: 0.6975 - val_acc: 0.6900\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5675 - acc: 0.7781 - val_loss: 0.8626 - val_acc: 0.5546\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8690 - acc: 0.6918 - val_loss: 2.1390 - val_acc: 0.5852\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6613 - acc: 0.7705 - val_loss: 1.3641 - val_acc: 0.5808\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.8312 - acc: 0.6656 - val_loss: 1.3136 - val_acc: 0.5983\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7383 - acc: 0.7158 - val_loss: 2.3726 - val_acc: 0.5764\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6659 - acc: 0.7902 - val_loss: 1.1656 - val_acc: 0.4192\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.8796 - acc: 0.5825 - val_loss: 0.7735 - val_acc: 0.6594\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.4949 - acc: 0.7541 - val_loss: 0.8691 - val_acc: 0.5415\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.6409 - acc: 0.6918 - val_loss: 1.4424 - val_acc: 0.3712\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.0708 - acc: 0.5989 - val_loss: 1.6089 - val_acc: 0.3886\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6946 - acc: 0.6721 - val_loss: 1.1856 - val_acc: 0.5895\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.5422 - acc: 0.7169 - val_loss: 0.7947 - val_acc: 0.6157\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6146 - acc: 0.6656 - val_loss: 1.8623 - val_acc: 0.3581\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0411 - acc: 0.6448 - val_loss: 2.1616 - val_acc: 0.5721\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7012 - acc: 0.6918 - val_loss: 2.5123 - val_acc: 0.2358\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.3689 - acc: 0.5421 - val_loss: 1.0959 - val_acc: 0.4367\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.6041 - acc: 0.7005 - val_loss: 0.7193 - val_acc: 0.6681\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.4509 - acc: 0.8197 - val_loss: 0.8990 - val_acc: 0.6201\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.8761 - acc: 0.6361 - val_loss: 1.2655 - val_acc: 0.5895\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.0389 - acc: 0.6678 - val_loss: 0.9519 - val_acc: 0.5764\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5641 - acc: 0.7672 - val_loss: 1.2972 - val_acc: 0.4891\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.7802 - acc: 0.6240 - val_loss: 1.1728 - val_acc: 0.6507\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7773 - acc: 0.6885 - val_loss: 1.2191 - val_acc: 0.4323\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4530 - acc: 0.7923 - val_loss: 0.8813 - val_acc: 0.5415\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7731 - acc: 0.6710 - val_loss: 0.6845 - val_acc: 0.6812\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.5872 - acc: 0.7628 - val_loss: 2.1277 - val_acc: 0.3493\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 2.1996 - acc: 0.5224 - val_loss: 1.8697 - val_acc: 0.6026\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7386 - acc: 0.7574 - val_loss: 0.8522 - val_acc: 0.6463\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.3457 - acc: 0.8831 - val_loss: 2.0942 - val_acc: 0.3799\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7498 - acc: 0.7005 - val_loss: 0.8313 - val_acc: 0.6419\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6504 - acc: 0.6820 - val_loss: 0.9592 - val_acc: 0.6201\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4416 - acc: 0.7639 - val_loss: 1.3884 - val_acc: 0.6026\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.4650 - acc: 0.5694 - val_loss: 1.0549 - val_acc: 0.6026\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.4988 - acc: 0.7738 - val_loss: 0.7934 - val_acc: 0.6507\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6339 - acc: 0.7978 - val_loss: 1.9801 - val_acc: 0.6376\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9223 - acc: 0.7377 - val_loss: 0.6945 - val_acc: 0.6550\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.5813 - acc: 0.6940 - val_loss: 0.9244 - val_acc: 0.6070\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6406 - acc: 0.7290 - val_loss: 0.9129 - val_acc: 0.5633\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.7770 - acc: 0.6699 - val_loss: 1.4103 - val_acc: 0.4148\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.3555 - acc: 0.6973 - val_loss: 0.8768 - val_acc: 0.6376\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6628 - acc: 0.7071 - val_loss: 1.2999 - val_acc: 0.5153\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4730 - acc: 0.7519 - val_loss: 1.0440 - val_acc: 0.5284\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5347 - acc: 0.7432 - val_loss: 0.9918 - val_acc: 0.5590\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.6092 - acc: 0.7071 - val_loss: 1.2511 - val_acc: 0.4236\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.3107 - acc: 0.5475 - val_loss: 0.7906 - val_acc: 0.6550\n",
            "Epoch 801/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.3934 - acc: 0.8721 - val_loss: 0.9172 - val_acc: 0.6288\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4622 - acc: 0.8240 - val_loss: 0.7249 - val_acc: 0.6638\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.4834 - acc: 0.8120 - val_loss: 1.6962 - val_acc: 0.3843\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.4090 - acc: 0.5661 - val_loss: 0.7722 - val_acc: 0.6681\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5496 - acc: 0.7803 - val_loss: 0.8752 - val_acc: 0.6157\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5250 - acc: 0.7180 - val_loss: 1.2911 - val_acc: 0.4236\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4250 - acc: 0.8055 - val_loss: 1.5611 - val_acc: 0.5764\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.1350 - acc: 0.6383 - val_loss: 1.4710 - val_acc: 0.5764\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4300 - acc: 0.8612 - val_loss: 0.7307 - val_acc: 0.6856\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5022 - acc: 0.7869 - val_loss: 0.8178 - val_acc: 0.6332\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7839 - acc: 0.7475 - val_loss: 0.8763 - val_acc: 0.5284\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7165 - acc: 0.6601 - val_loss: 1.5175 - val_acc: 0.4061\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.0896 - acc: 0.6142 - val_loss: 2.4192 - val_acc: 0.5721\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 3.9424 - acc: 0.4951 - val_loss: 2.0286 - val_acc: 0.5808\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6908 - acc: 0.7891 - val_loss: 0.8293 - val_acc: 0.6245\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.4790 - acc: 0.7825 - val_loss: 0.8935 - val_acc: 0.5677\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6270 - acc: 0.7115 - val_loss: 1.9141 - val_acc: 0.3493\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.2273 - acc: 0.6437 - val_loss: 0.7750 - val_acc: 0.6594\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.4571 - acc: 0.8437 - val_loss: 0.9726 - val_acc: 0.5939\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.7908 - acc: 0.7257 - val_loss: 1.5568 - val_acc: 0.3843\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 0.9432 - acc: 0.6066 - val_loss: 0.8409 - val_acc: 0.6507\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4547 - acc: 0.8306 - val_loss: 1.4858 - val_acc: 0.5764\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.8878 - acc: 0.6568 - val_loss: 2.2176 - val_acc: 0.5546\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1307 - acc: 0.6645 - val_loss: 0.7051 - val_acc: 0.6769\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.5721 - acc: 0.7126 - val_loss: 0.7222 - val_acc: 0.6769\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4622 - acc: 0.7880 - val_loss: 0.9606 - val_acc: 0.6026\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.5806 - acc: 0.7432 - val_loss: 2.1053 - val_acc: 0.6201\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1019 - acc: 0.7169 - val_loss: 1.4274 - val_acc: 0.4017\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7240 - acc: 0.6896 - val_loss: 0.7993 - val_acc: 0.6419\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.3230 - acc: 0.8557 - val_loss: 2.0186 - val_acc: 0.3930\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7050 - acc: 0.7607 - val_loss: 0.7943 - val_acc: 0.6288\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.5222 - acc: 0.7749 - val_loss: 3.8982 - val_acc: 0.3493\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.6174 - acc: 0.4940 - val_loss: 2.0893 - val_acc: 0.6507\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1396 - acc: 0.7180 - val_loss: 0.9936 - val_acc: 0.5459\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4733 - acc: 0.7814 - val_loss: 0.9193 - val_acc: 0.6157\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.3114 - acc: 0.8973 - val_loss: 0.8604 - val_acc: 0.6376\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.8510 - acc: 0.6995 - val_loss: 0.7140 - val_acc: 0.6681\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.4509 - acc: 0.7945 - val_loss: 1.3878 - val_acc: 0.5895\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5795 - acc: 0.7148 - val_loss: 1.6422 - val_acc: 0.3974\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1265 - acc: 0.5880 - val_loss: 0.8242 - val_acc: 0.6856\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5849 - acc: 0.7705 - val_loss: 0.7855 - val_acc: 0.6507\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4689 - acc: 0.7825 - val_loss: 1.7126 - val_acc: 0.5721\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.5934 - acc: 0.5519 - val_loss: 1.3302 - val_acc: 0.6376\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.3284 - acc: 0.6940 - val_loss: 3.6795 - val_acc: 0.5721\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.8897 - acc: 0.6131 - val_loss: 1.0567 - val_acc: 0.6594\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.5441 - acc: 0.6776 - val_loss: 6.1633 - val_acc: 0.3493\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.3605 - acc: 0.5530 - val_loss: 7.5637 - val_acc: 0.3493\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.9714 - acc: 0.6590 - val_loss: 1.0608 - val_acc: 0.6594\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.5538 - acc: 0.6197 - val_loss: 1.4954 - val_acc: 0.6114\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.5564 - acc: 0.6251 - val_loss: 2.0323 - val_acc: 0.6245\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.4871 - acc: 0.6721 - val_loss: 3.5621 - val_acc: 0.5721\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.2256 - acc: 0.5650 - val_loss: 2.4317 - val_acc: 0.5764\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.7482 - acc: 0.6186 - val_loss: 0.8265 - val_acc: 0.6900\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 1.3454 - acc: 0.7126 - val_loss: 1.7432 - val_acc: 0.6026\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.6435 - acc: 0.6383 - val_loss: 1.3943 - val_acc: 0.4017\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.5175 - acc: 0.6131 - val_loss: 1.1740 - val_acc: 0.6638\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.8358 - acc: 0.6590 - val_loss: 1.2370 - val_acc: 0.5459\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.6602 - acc: 0.6383 - val_loss: 1.9607 - val_acc: 0.5895\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2193 - acc: 0.6874 - val_loss: 3.5858 - val_acc: 0.5808\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.4174 - acc: 0.7191 - val_loss: 2.8574 - val_acc: 0.5808\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.4625 - acc: 0.5541 - val_loss: 1.8192 - val_acc: 0.6638\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0724 - acc: 0.7530 - val_loss: 3.6496 - val_acc: 0.6070\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.4530 - acc: 0.7333 - val_loss: 2.7401 - val_acc: 0.5721\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.0803 - acc: 0.5705 - val_loss: 3.9086 - val_acc: 0.5808\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.3017 - acc: 0.7585 - val_loss: 0.9441 - val_acc: 0.6550\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.2935 - acc: 0.6699 - val_loss: 1.5514 - val_acc: 0.4934\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.3175 - acc: 0.6798 - val_loss: 2.1358 - val_acc: 0.6157\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.4921 - acc: 0.6579 - val_loss: 2.2620 - val_acc: 0.4585\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.5157 - acc: 0.7027 - val_loss: 0.8450 - val_acc: 0.6812\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.5399 - acc: 0.6470 - val_loss: 3.9810 - val_acc: 0.5939\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.3443 - acc: 0.7224 - val_loss: 1.3788 - val_acc: 0.4760\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.3259 - acc: 0.6896 - val_loss: 3.6515 - val_acc: 0.3581\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.5688 - acc: 0.6721 - val_loss: 1.6027 - val_acc: 0.4454\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.5425 - acc: 0.6601 - val_loss: 0.7779 - val_acc: 0.6769\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1767 - acc: 0.7038 - val_loss: 3.4084 - val_acc: 0.3537\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.1657 - acc: 0.7060 - val_loss: 2.0433 - val_acc: 0.4105\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.3140 - acc: 0.5978 - val_loss: 1.4695 - val_acc: 0.6070\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1859 - acc: 0.6404 - val_loss: 0.8959 - val_acc: 0.6681\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.8350 - acc: 0.7410 - val_loss: 0.9297 - val_acc: 0.5852\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9523 - acc: 0.7093 - val_loss: 2.4493 - val_acc: 0.5852\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.9178 - acc: 0.6459 - val_loss: 0.9012 - val_acc: 0.6463\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.0715 - acc: 0.7005 - val_loss: 1.2717 - val_acc: 0.6507\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5116 - acc: 0.8372 - val_loss: 3.5596 - val_acc: 0.3537\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.4374 - acc: 0.4678 - val_loss: 0.8944 - val_acc: 0.5153\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.8735 - acc: 0.5978 - val_loss: 1.1074 - val_acc: 0.5983\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.0022 - acc: 0.6590 - val_loss: 0.7477 - val_acc: 0.6769\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7343 - acc: 0.7661 - val_loss: 1.7737 - val_acc: 0.4148\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.9419 - acc: 0.7115 - val_loss: 7.0038 - val_acc: 0.3493\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 1.2408 - acc: 0.7694 - val_loss: 3.1534 - val_acc: 0.5721\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.4831 - acc: 0.6131 - val_loss: 2.0632 - val_acc: 0.5808\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2602 - acc: 0.6273 - val_loss: 0.9834 - val_acc: 0.6943\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.9540 - acc: 0.7585 - val_loss: 1.4035 - val_acc: 0.5939\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.2187 - acc: 0.6667 - val_loss: 1.7354 - val_acc: 0.4148\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8284 - acc: 0.6984 - val_loss: 1.9584 - val_acc: 0.4105\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.3085 - acc: 0.5825 - val_loss: 1.4235 - val_acc: 0.6769\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7638 - acc: 0.7508 - val_loss: 2.1189 - val_acc: 0.5721\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.1495 - acc: 0.6525 - val_loss: 1.3436 - val_acc: 0.6157\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.3180 - acc: 0.6077 - val_loss: 1.6283 - val_acc: 0.5895\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 1.0384 - acc: 0.6842 - val_loss: 1.5403 - val_acc: 0.5939\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6462 - acc: 0.7202 - val_loss: 2.5996 - val_acc: 0.5808\n",
            "Epoch 901/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 1.0197 - acc: 0.6667 - val_loss: 1.8554 - val_acc: 0.6026\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6303 - acc: 0.8109 - val_loss: 1.1206 - val_acc: 0.6157\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.6560 - acc: 0.5967 - val_loss: 1.3546 - val_acc: 0.6026\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.1505 - acc: 0.6481 - val_loss: 1.0977 - val_acc: 0.6681\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.4499 - acc: 0.6153 - val_loss: 1.2375 - val_acc: 0.6769\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.3554 - acc: 0.6164 - val_loss: 2.7330 - val_acc: 0.5721\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1340 - acc: 0.6656 - val_loss: 1.9048 - val_acc: 0.4672\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.2263 - acc: 0.6579 - val_loss: 0.9309 - val_acc: 0.6769\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7312 - acc: 0.7421 - val_loss: 0.7981 - val_acc: 0.6419\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.4245 - acc: 0.6678 - val_loss: 1.1202 - val_acc: 0.6026\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.8309 - acc: 0.7388 - val_loss: 1.1201 - val_acc: 0.5197\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2163 - acc: 0.5956 - val_loss: 0.9414 - val_acc: 0.5284\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.2246 - acc: 0.6459 - val_loss: 0.9331 - val_acc: 0.6812\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1324 - acc: 0.6776 - val_loss: 2.0386 - val_acc: 0.3799\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0134 - acc: 0.6721 - val_loss: 1.0015 - val_acc: 0.5895\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0507 - acc: 0.6689 - val_loss: 0.8664 - val_acc: 0.6332\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7316 - acc: 0.7727 - val_loss: 0.7473 - val_acc: 0.6769\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.2447 - acc: 0.7060 - val_loss: 2.1028 - val_acc: 0.5895\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.9299 - acc: 0.6732 - val_loss: 0.8574 - val_acc: 0.6725\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.9580 - acc: 0.6798 - val_loss: 1.8429 - val_acc: 0.5764\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9854 - acc: 0.6962 - val_loss: 1.0706 - val_acc: 0.5983\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9180 - acc: 0.6831 - val_loss: 2.8079 - val_acc: 0.5721\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.3354 - acc: 0.6339 - val_loss: 2.0967 - val_acc: 0.5808\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.0485 - acc: 0.6437 - val_loss: 2.6017 - val_acc: 0.5808\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6307 - acc: 0.8197 - val_loss: 2.3009 - val_acc: 0.3843\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.9856 - acc: 0.6842 - val_loss: 0.8740 - val_acc: 0.6114\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4977 - acc: 0.7617 - val_loss: 1.2183 - val_acc: 0.6725\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.4707 - acc: 0.6317 - val_loss: 0.8847 - val_acc: 0.6376\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7030 - acc: 0.7530 - val_loss: 1.8669 - val_acc: 0.6070\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.8209 - acc: 0.7366 - val_loss: 0.7884 - val_acc: 0.6769\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.9799 - acc: 0.6863 - val_loss: 1.1092 - val_acc: 0.5502\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6832 - acc: 0.7377 - val_loss: 2.7527 - val_acc: 0.3537\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.1038 - acc: 0.6240 - val_loss: 0.8428 - val_acc: 0.6900\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6864 - acc: 0.7705 - val_loss: 2.3077 - val_acc: 0.5764\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7805 - acc: 0.6984 - val_loss: 2.2622 - val_acc: 0.5939\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7814 - acc: 0.6852 - val_loss: 2.7305 - val_acc: 0.5721\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.6769 - acc: 0.7967 - val_loss: 1.0512 - val_acc: 0.5459\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.9854 - acc: 0.6383 - val_loss: 1.0247 - val_acc: 0.4017\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8550 - acc: 0.6197 - val_loss: 1.1055 - val_acc: 0.5371\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5037 - acc: 0.7464 - val_loss: 2.0069 - val_acc: 0.3886\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7852 - acc: 0.6667 - val_loss: 0.8630 - val_acc: 0.6594\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6995 - acc: 0.7093 - val_loss: 1.3819 - val_acc: 0.3188\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 1.5291 - acc: 0.5497 - val_loss: 2.9369 - val_acc: 0.3537\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9737 - acc: 0.6579 - val_loss: 0.7700 - val_acc: 0.6943\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5879 - acc: 0.8153 - val_loss: 1.9909 - val_acc: 0.4279\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.9965 - acc: 0.6339 - val_loss: 0.8387 - val_acc: 0.6638\n",
            "Epoch 947/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6069 - acc: 0.8098 - val_loss: 0.8049 - val_acc: 0.6507\n",
            "Epoch 948/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.7784 - acc: 0.7377 - val_loss: 1.1854 - val_acc: 0.5546\n",
            "Epoch 949/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.4503 - acc: 0.6448 - val_loss: 0.7985 - val_acc: 0.6812\n",
            "Epoch 950/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7189 - acc: 0.7268 - val_loss: 1.9293 - val_acc: 0.5852\n",
            "Epoch 951/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4697 - acc: 0.8284 - val_loss: 1.0072 - val_acc: 0.6332\n",
            "Epoch 952/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.7212 - acc: 0.6940 - val_loss: 1.4657 - val_acc: 0.5895\n",
            "Epoch 953/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.9135 - acc: 0.6393 - val_loss: 1.5509 - val_acc: 0.6332\n",
            "Epoch 954/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6463 - acc: 0.7322 - val_loss: 3.3819 - val_acc: 0.1354\n",
            "Epoch 955/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.8098 - acc: 0.5137 - val_loss: 1.6710 - val_acc: 0.5895\n",
            "Epoch 956/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.0228 - acc: 0.6044 - val_loss: 1.7269 - val_acc: 0.5895\n",
            "Epoch 957/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5835 - acc: 0.7410 - val_loss: 1.7808 - val_acc: 0.5895\n",
            "Epoch 958/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7682 - acc: 0.6962 - val_loss: 0.9708 - val_acc: 0.6332\n",
            "Epoch 959/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5585 - acc: 0.7399 - val_loss: 1.8767 - val_acc: 0.5808\n",
            "Epoch 960/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.8253 - acc: 0.7607 - val_loss: 1.5571 - val_acc: 0.5590\n",
            "Epoch 961/1000\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.6826 - acc: 0.7333 - val_loss: 1.2255 - val_acc: 0.6026\n",
            "Epoch 962/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6094 - acc: 0.7399 - val_loss: 0.9783 - val_acc: 0.6594\n",
            "Epoch 963/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.6963 - acc: 0.7311 - val_loss: 1.5172 - val_acc: 0.5939\n",
            "Epoch 964/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7576 - acc: 0.6754 - val_loss: 1.1412 - val_acc: 0.5677\n",
            "Epoch 965/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.5894 - acc: 0.7322 - val_loss: 1.4807 - val_acc: 0.4367\n",
            "Epoch 966/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5788 - acc: 0.7891 - val_loss: 0.7103 - val_acc: 0.6725\n",
            "Epoch 967/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.6357 - acc: 0.8164 - val_loss: 2.1115 - val_acc: 0.3886\n",
            "Epoch 968/1000\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.7271 - acc: 0.7552 - val_loss: 2.0326 - val_acc: 0.4236\n",
            "Epoch 969/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7685 - acc: 0.7115 - val_loss: 0.7439 - val_acc: 0.6681\n",
            "Epoch 970/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9699 - acc: 0.7082 - val_loss: 3.2463 - val_acc: 0.5764\n",
            "Epoch 971/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.2687 - acc: 0.6328 - val_loss: 0.8656 - val_acc: 0.6026\n",
            "Epoch 972/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.2644 - acc: 0.9038 - val_loss: 2.3101 - val_acc: 0.3581\n",
            "Epoch 973/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7167 - acc: 0.7333 - val_loss: 1.0208 - val_acc: 0.5284\n",
            "Epoch 974/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5620 - acc: 0.7825 - val_loss: 1.0647 - val_acc: 0.6114\n",
            "Epoch 975/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5627 - acc: 0.7508 - val_loss: 0.7508 - val_acc: 0.6943\n",
            "Epoch 976/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.8240 - acc: 0.6831 - val_loss: 0.8575 - val_acc: 0.6812\n",
            "Epoch 977/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5816 - acc: 0.7770 - val_loss: 1.0698 - val_acc: 0.6157\n",
            "Epoch 978/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.6469 - acc: 0.5311 - val_loss: 1.1353 - val_acc: 0.5939\n",
            "Epoch 979/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6322 - acc: 0.7617 - val_loss: 1.1470 - val_acc: 0.6070\n",
            "Epoch 980/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7287 - acc: 0.7770 - val_loss: 1.1843 - val_acc: 0.6288\n",
            "Epoch 981/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9810 - acc: 0.6798 - val_loss: 0.8555 - val_acc: 0.6769\n",
            "Epoch 982/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5809 - acc: 0.7880 - val_loss: 1.2936 - val_acc: 0.6201\n",
            "Epoch 983/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9769 - acc: 0.6667 - val_loss: 0.8205 - val_acc: 0.6769\n",
            "Epoch 984/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.4256 - acc: 0.8044 - val_loss: 1.6310 - val_acc: 0.5895\n",
            "Epoch 985/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5511 - acc: 0.8033 - val_loss: 2.7564 - val_acc: 0.5328\n",
            "Epoch 986/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.7349 - acc: 0.7770 - val_loss: 2.1795 - val_acc: 0.5808\n",
            "Epoch 987/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.1881 - acc: 0.5770 - val_loss: 1.8498 - val_acc: 0.5852\n",
            "Epoch 988/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5229 - acc: 0.7825 - val_loss: 1.6836 - val_acc: 0.5983\n",
            "Epoch 989/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6638 - acc: 0.7235 - val_loss: 0.7559 - val_acc: 0.6987\n",
            "Epoch 990/1000\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.5683 - acc: 0.7421 - val_loss: 0.8523 - val_acc: 0.6725\n",
            "Epoch 991/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6730 - acc: 0.7421 - val_loss: 5.4677 - val_acc: 0.0917\n",
            "Epoch 992/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.2851 - acc: 0.6579 - val_loss: 0.7404 - val_acc: 0.6725\n",
            "Epoch 993/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.3080 - acc: 0.8940 - val_loss: 2.0603 - val_acc: 0.4017\n",
            "Epoch 994/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.5011 - acc: 0.8000 - val_loss: 0.7450 - val_acc: 0.6725\n",
            "Epoch 995/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6290 - acc: 0.7727 - val_loss: 0.7065 - val_acc: 0.6900\n",
            "Epoch 996/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5719 - acc: 0.7705 - val_loss: 0.7114 - val_acc: 0.7074\n",
            "Epoch 997/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.5823 - acc: 0.8000 - val_loss: 1.1043 - val_acc: 0.5546\n",
            "Epoch 998/1000\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5604 - acc: 0.7333 - val_loss: 0.7629 - val_acc: 0.6594\n",
            "Epoch 999/1000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.7185 - acc: 0.7169 - val_loss: 1.8876 - val_acc: 0.5197\n",
            "Epoch 1000/1000\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7445 - acc: 0.7060 - val_loss: 2.4362 - val_acc: 0.3755\n",
            "Train: 0.423, Test: 0.376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nestimator = KerasClassifier(build_fn=model, epochs=975, batch_size=128, verbose=0)\\nkfold = KFold(n_splits=5, shuffle=True, random_state=1)\\nresults = cross_val_score(estimator, all_x_train, txtr_y_train, cv=kfold, scoring=\\'accuracy\\')\\n\\nprint(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDGpoZ7V5PeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}